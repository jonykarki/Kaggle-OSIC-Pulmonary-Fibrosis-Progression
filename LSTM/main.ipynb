{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath(os.pardir) not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath(os.pardir))\n",
    "import CONFIG\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import random\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MAX_SCALER = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CONFIG.CFG.DATA.BASE\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "SCALE_COLUMNS = ['Weeks', 'FVC', 'Percent', 'Age'] #'Percent'\n",
    "SCALE_COLUMNS = ['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']\n",
    "SEX_COLUMNS = ['Male', 'Female']\n",
    "SMOKING_STATUS_COLUMNS = ['Currently smokes', 'Ex-smoker', 'Never smoked']\n",
    "FV = SCALE_COLUMNS + SEX_COLUMNS + SMOKING_STATUS_COLUMNS\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "sub_df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "# remove the duplicates from the train_df\n",
    "train_df.drop_duplicates(keep=False, inplace=True, subset=['Patient', 'Weeks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_Week</th>\n      <th>FVC</th>\n      <th>Confidence</th>\n      <th>Patient</th>\n      <th>Weeks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00419637202311204720264_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00421637202311550012437_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00421637202311550012437</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00422637202311677017371_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00422637202311677017371</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00423637202312137826377_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00423637202312137826377</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00426637202313170790466_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00426637202313170790466</td>\n      <td>-12</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    Patient_Week   FVC  ...                    Patient Weeks\n0  ID00419637202311204720264_-12  2000  ...  ID00419637202311204720264   -12\n1  ID00421637202311550012437_-12  2000  ...  ID00421637202311550012437   -12\n2  ID00422637202311677017371_-12  2000  ...  ID00422637202311677017371   -12\n3  ID00423637202312137826377_-12  2000  ...  ID00423637202312137826377   -12\n4  ID00426637202313170790466_-12  2000  ...  ID00426637202313170790466   -12\n\n[5 rows x 5 columns]"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# extract the Patient and weeks from the Patient_Week column\n",
    "sub_df['Patient'] = sub_df['Patient_Week'].apply(lambda x: x.split('_')[0])\n",
    "sub_df['Weeks'] = sub_df['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00419637202311204720264_-12</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-12</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00419637202311204720264_-11</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-11</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00419637202311204720264_-10</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-10</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00419637202311204720264_-9</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-9</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00419637202311204720264_-8</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-8</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    Patient_Week  Confidence  ...   Sex  SmokingStatus\n0  ID00419637202311204720264_-12         100  ...  Male      Ex-smoker\n1  ID00419637202311204720264_-11         100  ...  Male      Ex-smoker\n2  ID00419637202311204720264_-10         100  ...  Male      Ex-smoker\n3   ID00419637202311204720264_-9         100  ...  Male      Ex-smoker\n4   ID00419637202311204720264_-8         100  ...  Male      Ex-smoker\n\n[5 rows x 9 columns]"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# merge the sub_df with the test_df\n",
    "sub_df = sub_df.drop('FVC', axis=1).merge(test_df.drop('Weeks', axis=1), on='Patient')\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['FROM'] = 'train'\n",
    "test_df['FROM'] = 'val'\n",
    "sub_df['FROM'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = train_df.append([test_df, sub_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize base_week column\n",
    "combined_df['Base_Week'] = combined_df['Weeks']\n",
    "# make the weeks from sub_df to be np.nan so that when we calculate the base_week it comes from the test_df\n",
    "combined_df.loc[combined_df['FROM'] == 'test', 'Base_Week'] = np.nan\n",
    "# now calculate the min for each patient group and set it to the Base_Week column\n",
    "combined_df['Base_Week'] = combined_df.groupby('Patient')['Base_Week'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the base_df (where the Base_Week == the min_week we calculated) so that we can get the base_fvc, base_age and base_percentage\n",
    "base_df = combined_df[combined_df['Weeks'] == combined_df['Base_Week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n"
    }
   ],
   "source": [
    "base_df.rename(columns={\n",
    "    'FVC': 'Base_FVC',\n",
    "    'Percent': 'Base_Percent',\n",
    "    'Age': 'Base_Age'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.merge(base_df[['Patient', 'Base_FVC', 'Base_Percent', 'Base_Age']], on='Patient', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Weeks_Passed'] = combined_df['Weeks'] - combined_df['Base_Week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MinMaxScaler(copy=True, feature_range=(0, 1))"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "MIN_MAX_SCALER.fit(combined_df[combined_df['FROM'] == 'train'][['Weeks_Passed', 'FVC', 'Percent', 'Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']] = MIN_MAX_SCALER.transform(combined_df[['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categoricals into dummies\n",
    "combined_df['Sex'] = pd.Categorical(combined_df['Sex'], categories=SEX_COLUMNS)\n",
    "combined_df['SmokingStatus'] = pd.Categorical(combined_df['SmokingStatus'], categories=SMOKING_STATUS_COLUMNS)\n",
    "combined_df = combined_df.join(pd.get_dummies(combined_df['Sex']))\n",
    "combined_df = combined_df.join(pd.get_dummies(combined_df['SmokingStatus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n      <th>Male</th>\n      <th>Female</th>\n      <th>Currently smokes</th>\n      <th>Ex-smoker</th>\n      <th>Never smoked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00007637202177411956430</td>\n      <td>-4</td>\n      <td>2315</td>\n      <td>58.253649</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00007637202177411956430</td>\n      <td>5</td>\n      <td>2214</td>\n      <td>55.712129</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.142857</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00007637202177411956430</td>\n      <td>7</td>\n      <td>2061</td>\n      <td>51.862104</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.174603</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00007637202177411956430</td>\n      <td>9</td>\n      <td>2144</td>\n      <td>53.950679</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.206349</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00007637202177411956430</td>\n      <td>11</td>\n      <td>2069</td>\n      <td>52.063412</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.238095</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2265</th>\n      <td>ID00426637202313170790466</td>\n      <td>129</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_129</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.047619</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2266</th>\n      <td>ID00426637202313170790466</td>\n      <td>130</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_130</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.063492</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2267</th>\n      <td>ID00426637202313170790466</td>\n      <td>131</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_131</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.079365</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2268</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.095238</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2269</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.111111</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2270 rows × 20 columns</p>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Ex-smoker  Never smoked\n0     ID00007637202177411956430     -4  ...          1             0\n1     ID00007637202177411956430      5  ...          1             0\n2     ID00007637202177411956430      7  ...          1             0\n3     ID00007637202177411956430      9  ...          1             0\n4     ID00007637202177411956430     11  ...          1             0\n...                         ...    ...  ...        ...           ...\n2265  ID00426637202313170790466    129  ...          0             1\n2266  ID00426637202313170790466    130  ...          0             1\n2267  ID00426637202313170790466    131  ...          0             1\n2268  ID00426637202313170790466    132  ...          0             1\n2269  ID00426637202313170790466    133  ...          0             1\n\n[2270 rows x 20 columns]"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "combined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSICLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(OSICLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lc = nn.Linear(hidden_size, 50)\n",
    "        self.lc2 = nn.Linear(50, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out, _ = self.lstm(X)\n",
    "        out = self.lc(out)\n",
    "        out = self.lc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OSICLSTM(len(FV)+1, 200, 3, 1)\n",
    "model.to(DEVICE)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OSICLSTM(\n  (lstm): LSTM(10, 200, num_layers=3, batch_first=True)\n  (lc): Linear(in_features=200, out_features=50, bias=True)\n  (lc2): Linear(in_features=50, out_features=1, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n      <th>Male</th>\n      <th>Female</th>\n      <th>Currently smokes</th>\n      <th>Ex-smoker</th>\n      <th>Never smoked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00007637202177411956430</td>\n      <td>-4</td>\n      <td>2315</td>\n      <td>58.253649</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.26705</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00007637202177411956430</td>\n      <td>5</td>\n      <td>2214</td>\n      <td>55.712129</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.26705</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.142857</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00007637202177411956430</td>\n      <td>7</td>\n      <td>2061</td>\n      <td>51.862104</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.26705</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.174603</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00007637202177411956430</td>\n      <td>9</td>\n      <td>2144</td>\n      <td>53.950679</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.26705</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.206349</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00007637202177411956430</td>\n      <td>11</td>\n      <td>2069</td>\n      <td>52.063412</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.26705</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.238095</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                     Patient  Weeks  ...  Ex-smoker  Never smoked\n0  ID00007637202177411956430     -4  ...          1             0\n1  ID00007637202177411956430      5  ...          1             0\n2  ID00007637202177411956430      7  ...          1             0\n3  ID00007637202177411956430      9  ...          1             0\n4  ID00007637202177411956430     11  ...          1             0\n\n[5 rows x 20 columns]"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATIENTS = combined_df[combined_df['FROM'] == \"train\"]['Patient'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([2315., 2214., 2061., 2144., 2069., 2101., 2000., 2064., 2057.],\n       device='cuda:0')\n"
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for dimension 0 with size 9",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0b7362b768e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdata_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9 is out of bounds for dimension 0 with size 9"
     ]
    }
   ],
   "source": [
    "for patient in TRAIN_PATIENTS:\n",
    "    patient_data = combined_df[combined_df[\"Patient\"] == patient][FV].values\n",
    "    target = combined_df[combined_df['Patient'] == patient][\"FVC\"].values\n",
    "    target = torch.tensor(target).float().to(DEVICE)\n",
    "\n",
    "    print(target)\n",
    "\n",
    "    data_tensor = torch.zeros((patient_data.shape[0], 10))\n",
    "    data_tensor[:, 1:] = torch.tensor(patient_data).float()\n",
    "\n",
    "    for i, data in enumerate(data_tensor):\n",
    "        data = data.to(DEVICE)\n",
    "        out = model(data.view(1,1,-1))\n",
    "        data_tensor[i+1, 0] = out.cpu()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1, 1, 10]], which is output 0 of ViewBackward, is at version 9; expected version 8 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1581d8f418e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#     out = model(data.view(1, 1, -1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#     print(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpatient_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpatient_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1, 1, 10]], which is output 0 of ViewBackward, is at version 9; expected version 8 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    for patient in TRAIN_PATIENTS:\n",
    "        patient_loss = 0\n",
    "        model.zero_grad()\n",
    "\n",
    "        patient_data = combined_df[combined_df[\"Patient\"] == patient][FV].values\n",
    "        target = combined_df[combined_df[\"Patient\"] == patient]['FVC'].values\n",
    "\n",
    "        target = torch.tensor(target).float().to(DEVICE)\n",
    "\n",
    "        data_tensor = torch.zeros((patient_data.shape[0], len(FV)+1))\n",
    "        data_tensor[:, 1:] = torch.tensor(patient_data).float()\n",
    "        data_tensor = data_tensor.to(DEVICE)\n",
    "\n",
    "        loss = 0\n",
    "        for i in range(data_tensor.size()[0] - 1):\n",
    "            out = model(data_tensor[i].view(1,1,-1))\n",
    "            loss += loss_function(out.view(1), target[i+1])\n",
    "            data_tensor[i+1, 0] = out.view(1)\n",
    "            patient_loss += loss.item()\n",
    "        # for data in patient_data:\n",
    "        #     out = model(data.view(1, 1, -1))\n",
    "        #     print(out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += patient_loss/patient_data.shape[0]\n",
    "    print(f\"Epoch {epoch}, loss={total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([-12])"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "sample_u = torch.tensor([[-12, 3020, 73]])\n",
    "sample = torch.tensor(min_max_scaler.transform(sample_u)).float()\n",
    "sample_u[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ -14.31420559 2945.78741264   73.12457055]]\n[[ -12.         2945.78741264   73.        ]] \n\n[[ -14.38764644 2874.82694507   73.13517064]]\n[[ -11.         2874.82694507   73.        ]] \n\n[[ -13.16220379 2808.05978775   73.1353845 ]]\n[[ -10.         2808.05978775   73.        ]] \n\n[[ -11.92862207 2744.85890365   73.13483357]]\n[[  -9.         2744.85890365   73.        ]] \n\n[[ -10.68775672 2684.68925214   73.13386887]]\n[[  -8.         2684.68925214   73.        ]] \n\n[[  -9.44036448 2627.08802807   73.13275075]]\n[[  -7.         2627.08802807   73.        ]] \n\n[[  -8.1870088  2571.65270555   73.13167447]]\n[[  -6.         2571.65270555   73.        ]] \n\n[[  -6.92818731 2518.03074229   73.13079345]]\n[[  -5.         2518.03074229   73.        ]] \n\n[[  -5.66428661 2465.91077852   73.13021231]]\n[[  -4.         2465.91077852   73.        ]] \n\n[[  -4.39559871 2415.01715708   73.13001239]]\n[[  -3.         2415.01715708   73.        ]] \n\n[[  -3.12236214 2365.10494161   73.13024718]]\n[[-2.00000000e+00  2.36510494e+03  7.30000000e+01]] \n\n[[-1.84472084e+00  2.31595676e+03  7.31309469e+01]]\n[[-1.00000000e+00  2.31595676e+03  7.30000000e+01]] \n\n[[-5.62798202e-01  2.26737999e+03  7.31321324e+01]]\n[[   0.         2267.37998879   73.        ]] \n\n[[7.23339975e-01 2.21920458e+03 7.31338038e+01]]\n[[1.00000000e+00 2.21920458e+03 7.30000000e+01]] \n\n[[2.01366079e+00 2.17128224e+03 7.31359563e+01]]\n[[2.00000000e+00 2.17128224e+03 7.30000000e+01]] \n\n[[   3.30812722 2123.48528183   73.13857847]]\n[[   3.         2123.48528183   73.        ]] \n\n[[   4.60675985 2075.70567316   73.14164692]]\n[[   4.         2075.70567316   73.        ]] \n\n[[   5.90952575 2027.85416114   73.14513844]]\n[[   5.         2027.85416114   73.        ]] \n\n[[   7.21644756 1979.86116725   73.14902514]]\n[[   6.         1979.86116725   73.        ]] \n\n[[   8.52749237 1931.67446607   73.15327913]]\n[[   7.         1931.67446607   73.        ]] \n\n[[   9.84264579 1883.25993258   73.15786552]]\n[[   8.         1883.25993258   73.        ]] \n\n[[  11.16186669 1834.59963244   73.16275412]]\n[[   9.         1834.59963244   73.        ]] \n\n[[  12.48511395 1785.69115782   73.16791469]]\n[[  10.         1785.69115782   73.        ]] \n\n[[  13.81234232 1736.54604977   73.17331469]]\n[[  11.         1736.54604977   73.        ]] \n\n[[  15.14349011 1687.18805468   73.17892623]]\n[[  12.         1687.18805468   73.        ]] \n\n[[  16.47851825 1637.65063334   73.18471444]]\n[[  13.         1637.65063334   73.        ]] \n\n[[  17.8173959  1587.97413796   73.19065142]]\n[[  14.         1587.97413796   73.        ]] \n\n[[  19.16011688 1538.20365345   73.19671392]]\n[[  15.         1538.20365345   73.        ]] \n\n[[  20.50671616 1488.38501197   73.20286942]]\n[[  16.         1488.38501197   73.        ]] \n\n[[  21.85728627 1438.56172085   73.20909697]]\n[[  17.         1438.56172085   73.        ]] \n\n[[  23.21196294 1388.77189052   73.21537334]]\n[[  18.         1388.77189052   73.        ]] \n\n[[  24.5709703  1339.04316974   73.22167993]]\n[[  19.         1339.04316974   73.        ]] \n\n[[  25.93462914 1289.39050376   73.22800046]]\n[[  20.         1289.39050376   73.        ]] \n\n[[  27.30337954 1239.8118999    73.23432797]]\n[[  21.        1239.8118999   73.       ]] \n\n[[  28.67778698 1190.28410995   73.24066246]]\n[[  22.         1190.28410995   73.        ]] \n\n[[  30.0586226  1140.75864482   73.24701554]]\n[[  23.         1140.75864482   73.        ]] \n\n[[  31.44687963 1091.15695882   73.25341046]]\n[[  24.         1091.15695882   73.        ]] \n\n[[  32.84386384 1041.36513579   73.25988907]]\n[[  25.         1041.36513579   73.        ]] \n\n[[ 34.25129437 991.2270807   73.26651877]]\n[[ 26.        991.2270807  73.       ]] \n\n[[ 35.6714291  940.53522038  73.27338791]]\n[[ 27.         940.53522038  73.        ]] \n\n[[ 37.10729086 889.0185473   73.2806313 ]]\n[[ 28.        889.0185473  73.       ]] \n\n[[ 38.56292248 836.32601368  73.28842795]]\n[[ 29.         836.32601368  73.        ]] \n\n[[ 40.04384321 782.00344944  73.29703122]]\n[[ 30.         782.00344944  73.        ]] \n\n[[ 41.55768627 725.45885587  73.30678284]]\n[[ 31.         725.45885587  73.        ]] \n\n[[ 43.11518997 665.90993118  73.31816864]]\n[[ 32.         665.90993118  73.        ]] \n\n[[ 44.73181403 602.30635512  73.33187205]]\n[[ 33.         602.30635512  73.        ]] \n\n[[ 46.43048686 533.20541108  73.3488996 ]]\n[[ 34.         533.20541108  73.        ]] \n\n[[ 48.24635988 456.5654093   73.37075996]]\n[[ 35.        456.5654093  73.       ]] \n\n[[ 50.23570335 369.39663184  73.39983815]]\n[[ 36.         369.39663184  73.        ]] \n\n[[ 52.49344707 267.12150896  73.44006038]]\n[[ 37.         267.12150896  73.        ]] \n\n[[ 55.19056094 142.33980787  73.4983725 ]]\n[[ 38.         142.33980787  73.        ]] \n\n[[ 58.6614297  -17.77765608  73.58801532]]\n[[ 39.         -17.77765608  73.        ]] \n\n[[  63.63240504 -237.60960507   73.73701167]]\n[[  40.         -237.60960507   73.        ]] \n\n[[  71.90776622 -569.67553973   74.01271862]]\n[[  41.         -569.67553973   73.        ]] \n\n[[   88.75995922 -1149.41147709    74.60277402]]\n[[   42.         -1149.41147709    73.        ]] \n\n[[  131.60629773 -2434.52623248    76.05585808]]\n[[   43.         -2434.52623248    73.        ]] \n\n[[  234.56215191 -6710.49943829    78.5584231 ]]\n[[   44.         -6710.49943829    73.        ]] \n\n[[   315.43356895 -31391.23960304     72.23388636]]\n[[    45.         -31391.23960304     73.        ]] \n\n[[-9.60362689e+01 -2.11149145e+05 -1.00504699e+03]]\n[[ 4.60000000e+01 -2.11149145e+05  7.30000000e+01]] \n\n[[ 1.92733349e+03 -2.18720946e+05 -1.20893650e+02]]\n[[ 4.70000000e+01 -2.18720946e+05  7.30000000e+01]] \n\n[[ 1.93890044e+03 -2.19039545e+05 -1.19118209e+02]]\n[[ 4.80000000e+01 -2.19039545e+05  7.30000000e+01]] \n\n[[ 1.93828333e+03 -2.19026452e+05 -1.19220825e+02]]\n[[ 4.90000000e+01 -2.19026452e+05  7.30000000e+01]] \n\n[[ 1.93710821e+03 -2.18997969e+05 -1.19410809e+02]]\n[[ 5.00000000e+01 -2.18997969e+05  7.30000000e+01]] \n\n[[ 1.93590861e+03 -2.18968892e+05 -1.19603470e+02]]\n[[ 5.10000000e+01 -2.18968892e+05  7.30000000e+01]] \n\n[[ 1.93470915e+03 -2.18939878e+05 -1.19795071e+02]]\n[[ 5.20000000e+01 -2.18939878e+05  7.30000000e+01]] \n\n[[ 1.93351126e+03 -2.18910992e+05 -1.19985371e+02]]\n[[ 5.30000000e+01 -2.18910992e+05  7.30000000e+01]] \n\n[[ 1.93231535e+03 -2.18882212e+05 -1.20174182e+02]]\n[[ 5.40000000e+01 -2.18882212e+05  7.30000000e+01]] \n\n[[ 1.93112220e+03 -2.18853602e+05 -1.20361637e+02]]\n[[ 5.50000000e+01 -2.18853602e+05  7.30000000e+01]] \n\n[[ 1.92993128e+03 -2.18825098e+05 -1.20547808e+02]]\n[[ 5.60000000e+01 -2.18825098e+05  7.30000000e+01]] \n\n[[ 1.92874274e+03 -2.18796765e+05 -1.20732510e+02]]\n[[ 5.70000000e+01 -2.18796765e+05  7.30000000e+01]] \n\n[[ 1.92755775e+03 -2.18768516e+05 -1.20915668e+02]]\n[[ 5.80000000e+01 -2.18768516e+05  7.30000000e+01]] \n\n[[ 1.92637605e+03 -2.18740480e+05 -1.21097636e+02]]\n[[ 5.9000000e+01 -2.1874048e+05  7.3000000e+01]] \n\n[[ 1.92519764e+03 -2.18712593e+05 -1.21278098e+02]]\n[[ 6.00000000e+01 -2.18712593e+05  7.30000000e+01]] \n\n[[ 1.92402305e+03 -2.18684812e+05 -1.21457072e+02]]\n[[ 6.10000000e+01 -2.18684812e+05  7.30000000e+01]] \n\n[[ 1.92285267e+03 -2.18657265e+05 -1.21634614e+02]]\n[[ 6.20000000e+01 -2.18657265e+05  7.30000000e+01]] \n\n[[ 1.92168676e+03 -2.18629867e+05 -1.21810688e+02]]\n[[ 6.30000000e+01 -2.18629867e+05  7.30000000e+01]] \n\n[[ 1.92052533e+03 -2.18602638e+05 -1.21985329e+02]]\n[[ 6.40000000e+01 -2.18602638e+05  7.30000000e+01]] \n\n[[ 1.91936824e+03 -2.18575601e+05 -1.22158556e+02]]\n[[ 6.50000000e+01 -2.18575601e+05  7.30000000e+01]] \n\n[[ 1.91821668e+03 -2.18548798e+05 -1.22330297e+02]]\n[[ 6.60000000e+01 -2.18548798e+05  7.30000000e+01]] \n\n[[ 1.91707025e+03 -2.18522122e+05 -1.22500493e+02]]\n[[ 6.70000000e+01 -2.18522122e+05  7.30000000e+01]] \n\n[[ 1.91592974e+03 -2.18495702e+05 -1.22669313e+02]]\n[[ 6.80000000e+01 -2.18495702e+05  7.30000000e+01]] \n\n[[ 1.91479450e+03 -2.18469451e+05 -1.22836386e+02]]\n[[ 6.90000000e+01 -2.18469451e+05  7.30000000e+01]] \n\n[[ 1.91366584e+03 -2.18443435e+05 -1.23002379e+02]]\n[[ 7.00000000e+01 -2.18443435e+05  7.30000000e+01]] \n\n[[ 1.91254323e+03 -2.18417609e+05 -1.23166551e+02]]\n[[ 7.10000000e+01 -2.18417609e+05  7.30000000e+01]] \n\n[[ 1.91142694e+03 -2.18392039e+05 -1.23329346e+02]]\n[[ 7.20000000e+01 -2.18392039e+05  7.30000000e+01]] \n\n[[ 1.91031788e+03 -2.18366681e+05 -1.23490504e+02]]\n[[ 7.30000000e+01 -2.18366681e+05  7.30000000e+01]] \n\n[[ 1.90921541e+03 -2.18341536e+05 -1.23650342e+02]]\n[[ 7.40000000e+01 -2.18341536e+05  7.30000000e+01]] \n\n[[ 1.90812018e+03 -2.18316603e+05 -1.23808656e+02]]\n[[ 7.50000000e+01 -2.18316603e+05  7.30000000e+01]] \n\n[[ 1.90703231e+03 -2.18291926e+05 -1.23965351e+02]]\n[[ 7.60000000e+01 -2.18291926e+05  7.30000000e+01]] \n\n[[ 1.90595261e+03 -2.18267503e+05 -1.24120670e+02]]\n[[ 7.70000000e+01 -2.18267503e+05  7.30000000e+01]] \n\n[[ 1.90488054e+03 -2.18243314e+05 -1.24274427e+02]]\n[[ 7.80000000e+01 -2.18243314e+05  7.30000000e+01]] \n\n[[ 1.90381636e+03 -2.18219402e+05 -1.24426715e+02]]\n[[ 7.90000000e+01 -2.18219402e+05  7.30000000e+01]] \n\n[[ 1.90276048e+03 -2.18195681e+05 -1.24577348e+02]]\n[[ 8.00000000e+01 -2.18195681e+05  7.30000000e+01]] \n\n[[ 1.90171328e+03 -2.18172278e+05 -1.24726642e+02]]\n[[ 8.10000000e+01 -2.18172278e+05  7.30000000e+01]] \n\n[[ 1.90067438e+03 -2.18149131e+05 -1.24874448e+02]]\n[[ 8.20000000e+01 -2.18149131e+05  7.30000000e+01]] \n\n[[ 1.89964468e+03 -2.18126196e+05 -1.25020674e+02]]\n[[ 8.30000000e+01 -2.18126196e+05  7.30000000e+01]] \n\n[[ 1.89862407e+03 -2.18103559e+05 -1.25165393e+02]]\n[[ 8.40000000e+01 -2.18103559e+05  7.30000000e+01]] \n\n[[ 1.89761267e+03 -2.18081177e+05 -1.25308643e+02]]\n[[ 8.50000000e+01 -2.18081177e+05  7.30000000e+01]] \n\n[[ 1.89661022e+03 -2.18059114e+05 -1.25450387e+02]]\n[[ 8.60000000e+01 -2.18059114e+05  7.30000000e+01]] \n\n[[ 1.89561777e+03 -2.18037285e+05 -1.25590642e+02]]\n[[ 8.70000000e+01 -2.18037285e+05  7.30000000e+01]] \n\n[[ 1.89463519e+03 -2.18015795e+05 -1.25729504e+02]]\n[[ 8.80000000e+01 -2.18015795e+05  7.30000000e+01]] \n\n[[ 1.89366222e+03 -2.17994561e+05 -1.25866914e+02]]\n[[ 8.90000000e+01 -2.17994561e+05  7.30000000e+01]] \n\n[[ 1.89269925e+03 -2.17973561e+05 -1.26002726e+02]]\n[[ 9.00000000e+01 -2.17973561e+05  7.30000000e+01]] \n\n[[ 1.89174642e+03 -2.17952879e+05 -1.26137217e+02]]\n[[ 9.10000000e+01 -2.17952879e+05  7.30000000e+01]] \n\n[[ 1.89080385e+03 -2.17932495e+05 -1.26270220e+02]]\n[[ 9.20000000e+01 -2.17932495e+05  7.30000000e+01]] \n\n[[ 1.88987220e+03 -2.17912366e+05 -1.26401735e+02]]\n[[ 9.30000000e+01 -2.17912366e+05  7.30000000e+01]] \n\n[[ 1.88895043e+03 -2.17892599e+05 -1.26531800e+02]]\n[[ 9.40000000e+01 -2.17892599e+05  7.30000000e+01]] \n\n[[ 1.88803971e+03 -2.17873086e+05 -1.26660470e+02]]\n[[ 9.50000000e+01 -2.17873086e+05  7.30000000e+01]] \n\n[[ 1.88713978e+03 -2.17853892e+05 -1.26787709e+02]]\n[[ 9.60000000e+01 -2.17853892e+05  7.30000000e+01]] \n\n[[ 1.88625051e+03 -2.17834996e+05 -1.26913589e+02]]\n[[ 9.70000000e+01 -2.17834996e+05  7.30000000e+01]] \n\n[[ 1.88537243e+03 -2.17816355e+05 -1.27037945e+02]]\n[[ 9.80000000e+01 -2.17816355e+05  7.30000000e+01]] \n\n[[ 1.88450540e+03 -2.17798033e+05 -1.27161036e+02]]\n[[ 9.90000000e+01 -2.17798033e+05  7.30000000e+01]] \n\n[[ 1.88364943e+03 -2.17780029e+05 -1.27282696e+02]]\n[[ 1.00000000e+02 -2.17780029e+05  7.30000000e+01]] \n\n[[ 1.88280477e+03 -2.17762345e+05 -1.27402867e+02]]\n[[ 1.01000000e+02 -2.17762345e+05  7.30000000e+01]] \n\n[[ 1.88197104e+03 -2.17744937e+05 -1.27522053e+02]]\n[[ 1.02000000e+02 -2.17744937e+05  7.30000000e+01]] \n\n[[ 1.88114915e+03 -2.17727826e+05 -1.27639472e+02]]\n[[ 1.03000000e+02 -2.17727826e+05  7.30000000e+01]] \n\n[[ 1.88033819e+03 -2.17711013e+05 -1.27755776e+02]]\n[[ 1.04000000e+02 -2.17711013e+05  7.30000000e+01]] \n\n[[ 1.87953934e+03 -2.17694519e+05 -1.27870796e+02]]\n[[ 1.05000000e+02 -2.17694519e+05  7.30000000e+01]] \n\n[[ 1.87875154e+03 -2.17678364e+05 -1.27984459e+02]]\n[[ 1.06000000e+02 -2.17678364e+05  7.30000000e+01]] \n\n[[ 1.87797532e+03 -2.17662465e+05 -1.28096671e+02]]\n[[ 1.07000000e+02 -2.17662465e+05  7.30000000e+01]] \n\n"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(120):\n",
    "        out = model(sample.view(1,1,-1))\n",
    "        out = min_max_scaler.inverse_transform(out.squeeze(dim=0))\n",
    "        print(out)\n",
    "        prev_zero = sample_u[:,0]\n",
    "        prev_three = sample_u[:,2]\n",
    "        out[:, 0] = prev_zero + i\n",
    "        out[:, 2] = prev_three\n",
    "        print(out, \"\\n\")\n",
    "        sample = torch.tensor(min_max_scaler.transform(out)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(sample)\n",
    "    out = model(sample.view(1, 1, -1))\n",
    "    print(out)\n",
    "    sample = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input = torch.randn(2, 5, 4)\n",
    "    print(input)\n",
    "    print()\n",
    "    out = model(input)\n",
    "    print(out)\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}