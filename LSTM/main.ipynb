{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath(os.pardir) not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath(os.pardir))\n",
    "import CONFIG\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = CONFIG.CFG.DATA.BASE\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00007637202177411956430</td>\n      <td>-4</td>\n      <td>2315</td>\n      <td>58.253649</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00007637202177411956430</td>\n      <td>5</td>\n      <td>2214</td>\n      <td>55.712129</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00007637202177411956430</td>\n      <td>7</td>\n      <td>2061</td>\n      <td>51.862104</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00007637202177411956430</td>\n      <td>9</td>\n      <td>2144</td>\n      <td>53.950679</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00007637202177411956430</td>\n      <td>11</td>\n      <td>2069</td>\n      <td>52.063412</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(ROOT, \"train.csv\"))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f22e40df9a8>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSICLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(OSICLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        out, _ = self.lstm(X)\n",
    "        out = self.lc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OSICLSTM(4, 100, 1, 4)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([16, 4])\ntorch.Size([16, 4])\ntorch.Size([16])\ntorch.Size([16])\n"
    }
   ],
   "source": [
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "OSICLSTM(\n  (lstm): LSTM(4, 100, batch_first=True)\n  (lc): Linear(in_features=100, out_features=4, bias=True)\n)\n"
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_PATIENTS = train_df[\"Patient\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "OSICLSTM(\n  (lstm): LSTM(4, 100, batch_first=True)\n  (lc): Linear(in_features=100, out_features=4, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[-0.0150, -0.4470,  0.1776,  0.2869]]], grad_fn=<AddBackward0>)\n"
    }
   ],
   "source": [
    "for patient in ALL_PATIENTS:\n",
    "    patient_data = train_df[train_df[\"Patient\"] == patient][['Weeks', 'FVC', 'Percent', 'Age']].values\n",
    "    patient_data = torch.tensor(patient_data).float()\n",
    "\n",
    "    for data in patient_data:\n",
    "        out = model(data.view(1,1,-1))\n",
    "        print(out)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([1, 1, 4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\nEpoch 0, loss=1465597586.6549072\nEpoch 1, loss=1381502054.5233154\nEpoch 2, loss=1381502023.5220337\nEpoch 3, loss=1381502024.964386\nEpoch 4, loss=1381502024.553543\nEpoch 5, loss=1381502024.5938416\nEpoch 6, loss=1381502024.564148\nEpoch 7, loss=1381502024.905304\nEpoch 8, loss=1381502024.6339417\nEpoch 9, loss=1381502024.8549957\nEpoch 10, loss=1381502024.718628\nEpoch 11, loss=1381502024.9852295\nEpoch 12, loss=1381502024.670227\nEpoch 13, loss=1381502024.566986\nEpoch 14, loss=1381502024.84729\nEpoch 15, loss=1381502024.7083282\nEpoch 16, loss=1381502024.8101807\nEpoch 17, loss=1381502024.5385742\nEpoch 18, loss=1381502024.5575867\nEpoch 19, loss=1381502024.5376892\nEpoch 20, loss=1381502024.9707031\nEpoch 21, loss=1381502024.8598938\nEpoch 22, loss=1381502024.6609192\nEpoch 23, loss=1381502024.7033234\nEpoch 24, loss=1381502024.668274\nEpoch 25, loss=1381502024.5797424\nEpoch 26, loss=1381502024.7218323\nEpoch 27, loss=1381502024.5093079\nEpoch 28, loss=1381502024.7513733\nEpoch 29, loss=1381502024.5432434\nEpoch 30, loss=1381502024.5359497\nEpoch 31, loss=1381502024.5371704\nEpoch 32, loss=1381502024.737671\nEpoch 33, loss=1381502024.5222778\nEpoch 34, loss=1381502024.5369568\nEpoch 35, loss=1381502024.557495\nEpoch 36, loss=1381502024.5048523\nEpoch 37, loss=1381502024.5196533\nEpoch 38, loss=1381502024.5370483\nEpoch 39, loss=1381502024.7139893\nEpoch 40, loss=1381502024.5359497\nEpoch 41, loss=1381502024.7264404\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-536597b22f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#     out = model(data.view(1, 1, -1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#     print(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}, loss={total_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    for patient in ALL_PATIENTS:\n",
    "        model.zero_grad()\n",
    "\n",
    "        patient_data = train_df[train_df[\"Patient\"] == patient][['Weeks', 'FVC', 'Percent', 'Age']].values\n",
    "        patient_data = torch.tensor(patient_data).float()\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(patient_data.size()[0] - 1):\n",
    "            out = model(data.view(1,1,-1))\n",
    "            loss += loss_function(out, patient_data[i+1])\n",
    "            total_loss += loss.item()\n",
    "        # for data in patient_data:\n",
    "        #     out = model(data.view(1, 1, -1))\n",
    "        #     print(out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}, loss={total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[-0.5860,  1.3153, -1.0502, -0.5227],\n         [-1.1907, -1.2158, -0.4712, -0.1658],\n         [-0.9553,  0.9396, -1.2907,  0.4846],\n         [-0.1314, -0.4851,  0.1461,  0.1841],\n         [ 0.1598, -0.7560,  0.1895,  0.5957]],\n\n        [[-0.9853,  0.9842, -0.3083, -0.5643],\n         [ 1.4160, -0.1827,  0.5166, -0.1190],\n         [-0.0798, -0.3892, -0.3054,  0.2493],\n         [-0.3142, -2.8067, -1.8554, -0.9012],\n         [ 0.9378, -0.8356,  2.2742,  1.2010]]])\n\ntensor([[[ 0.1448, -0.0468, -0.0903, -0.0212,  0.0090, -0.0891, -0.0880,\n          -0.0046, -0.0033, -0.0360],\n         [ 0.2230, -0.0832, -0.1429, -0.0101,  0.0148, -0.1451, -0.1288,\n           0.0017,  0.0270, -0.0820],\n         [ 0.2773, -0.0919, -0.1637, -0.0215,  0.0170, -0.1744, -0.1577,\n          -0.0025,  0.0194, -0.1195],\n         [ 0.2993, -0.0928, -0.1835, -0.0177,  0.0165, -0.1946, -0.1785,\n          -0.0057,  0.0355, -0.1458],\n         [ 0.3126, -0.0837, -0.1999, -0.0143,  0.0147, -0.2093, -0.1937,\n          -0.0095,  0.0473, -0.1601]],\n\n        [[ 0.1357, -0.0425, -0.0999, -0.0131,  0.0073, -0.0960, -0.0851,\n          -0.0038,  0.0108, -0.0335],\n         [ 0.2189, -0.0527, -0.1535, -0.0193,  0.0162, -0.1617, -0.1410,\n          -0.0116,  0.0148, -0.0731],\n         [ 0.2675, -0.0645, -0.1814, -0.0214,  0.0227, -0.1921, -0.1700,\n          -0.0114,  0.0240, -0.1114],\n         [ 0.3069, -0.0987, -0.1883, -0.0043,  0.0287, -0.2002, -0.1780,\n           0.0025,  0.0456, -0.1440],\n         [ 0.3099, -0.0741, -0.2142, -0.0037,  0.0081, -0.2182, -0.1984,\n          -0.0061,  0.0680, -0.1598]]])\ntorch.Size([2, 5, 10])\n"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input = torch.randn(2, 5, 4)\n",
    "    print(input)\n",
    "    print()\n",
    "    out = model(input)\n",
    "    print(out)\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}