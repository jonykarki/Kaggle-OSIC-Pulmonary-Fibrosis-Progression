{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/carlossouza/osic-autoencoder-training\n",
    "import sys, os\n",
    "if os.path.abspath(os.pardir) not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath(os.pardir))\n",
    "import CONFIG\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from datetime import timedelta, datetime\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pydicom\n",
    "import pytest\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from skimage import measure, morphology, segmentation\n",
    "from time import time, sleep\n",
    "from tqdm import trange, tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, random_split, DistributedSampler, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = CONFIG.CFG.DATA.BASE\n",
    "test_dir = os.path.join(root_dir, \"test\")\n",
    "model_file = \"model.pt\"\n",
    "resize_dims = (40, 256, 256)\n",
    "clip_bounds = (-1000, 200)\n",
    "watershed_iterations = 1\n",
    "pre_calculated_mean = 0.02865046213070556\n",
    "latent_features = 10\n",
    "batch_size = 16\n",
    "learning_rate = 3e-5\n",
    "num_epochs = 10\n",
    "val_size = 0.2\n",
    "tensorboard_dir = \"runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTScansDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.patients = [p for p in self.root_dir.glob('*') if p.is_dir()]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image, metadata = self.load_scan(self.patients[idx])\n",
    "        sample = {\n",
    "            'image': image,\n",
    "            'metadata': metadata\n",
    "        }\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def save(self, path):\n",
    "        t0 = time()\n",
    "        Path(path).mkdir(exist_ok=True, parents=True)\n",
    "        print(\"Saving pre-procssed dataset to disk\")\n",
    "        sleep(1)\n",
    "        cum = 0\n",
    "\n",
    "        bar = trange(len(self))\n",
    "        for i in bar:\n",
    "            sample = self[i]\n",
    "            image, data = sample['image'], sample['metadata']\n",
    "            cum += torch.mean(image).item()\n",
    "\n",
    "            bar.set_description(f'Saving CT scan {data.PatientID}')\n",
    "            fname = Path(path) / f'{data.PatientID}.pt'\n",
    "            torch.save(image, fname)\n",
    "\n",
    "        sleep(1)\n",
    "        bar.close()\n",
    "\n",
    "        print(f'Done! Time {timedelta(seconds=time() - t0)})\\n',\n",
    "              f'Mean value: {cum / len(self)}')\n",
    "\n",
    "    def get_patient(self, patient_id):\n",
    "        patient_ids = [str(p.stem) for p in self.patients]\n",
    "        return self.__getitem__(patient_ids.index(patient_id))\n",
    "\n",
    "    @staticmethod\n",
    "    def load_scan(path):\n",
    "        slices = [pydicom.read_file(p) for p in path.glob('*.dcm')]\n",
    "        try:\n",
    "            slices.sort(key=lambda x: float(x.ImagePosition[2]))\n",
    "        except AttributeError:\n",
    "            warnings.warn('f {slices[0].PatientID} CT scan does not '\n",
    "                        f'have \"ImagePosition\". Assuming filenames are in the right scan order')\n",
    "        image = np.stack([s.pixel_array.astype(float) for s in slices])\n",
    "        return image, slices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropBoundingBox:\n",
    "    @staticmethod\n",
    "    def bounding_box(img3d: np.array):\n",
    "        mid_img = img3d[int(img3d.shape[0] / 2)]\n",
    "        same_first_row = (mid_img[0, :] == mid_img[0, 0]).all()\n",
    "        same_first_col = (mid_img[:, 0] == mid_img[0, 0]).all()\n",
    "        if same_first_col and same_first_row:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, data = sample['image'], sample['metadata']\n",
    "        if not self.bounding_box(image):\n",
    "            return sample\n",
    "\n",
    "        mid_img = image[int(image.shape[0] / 2)]\n",
    "        r_min, r_max = None, None\n",
    "        c_min, c_max = None, None\n",
    "        for row in range(mid_img.shape[0]):\n",
    "            if not (mid_img[row, :] == mid_img[0, 0]).all() and r_min is None:\n",
    "                r_min = row\n",
    "            if (mid_img[row, :] == mid_img[0, 0]).all() and r_max is None \\\n",
    "                    and r_min is not None:\n",
    "                r_max = row\n",
    "                break\n",
    "\n",
    "        for col in range(mid_img.shape[1]):\n",
    "            if not (mid_img[:, col] == mid_img[0, 0]).all() and c_min is None:\n",
    "                c_min = col\n",
    "            if (mid_img[:, col] == mid_img[0, 0]).all() and c_max is None \\\n",
    "                    and c_min is not None:\n",
    "                c_max = col\n",
    "                break\n",
    "\n",
    "        image = image[:, r_min:r_max, c_min:c_max]\n",
    "        return {'image': image, 'metadata': data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}