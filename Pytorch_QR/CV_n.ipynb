{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath(os.pardir) not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath(os.pardir))\n",
    "import CONFIG\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CONFIG.CFG.DATA.BASE\n",
    "K_FOLDS = 5\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-4\n",
    "NUM_EPOCHS = 1100\n",
    "# print loss every\n",
    "PRINT_EVERY = 50\n",
    "\n",
    "QUANTILES = [0.3, 0.5, 0.7]\n",
    "SCALE_COLUMNS = ['Weeks', 'FVC', 'Percent', 'Age'] #'Percent'\n",
    "SCALE_COLUMNS = ['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']\n",
    "SEX_COLUMNS = ['Male', 'Female']\n",
    "SMOKING_STATUS_COLUMNS = ['Currently smokes', 'Ex-smoker', 'Never smoked']\n",
    "FV = SEX_COLUMNS + SMOKING_STATUS_COLUMNS + SCALE_COLUMNS\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.KFold(K_FOLDS)\n",
    "MIN_MAX_SCALER = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "sub_df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "# remove the duplicates from the train_df\n",
    "train_df.drop_duplicates(keep=False, inplace=True, subset=['Patient', 'Weeks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_Week</th>\n      <th>FVC</th>\n      <th>Confidence</th>\n      <th>Patient</th>\n      <th>Weeks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00419637202311204720264_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00421637202311550012437_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00421637202311550012437</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00422637202311677017371_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00422637202311677017371</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00423637202312137826377_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00423637202312137826377</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00426637202313170790466_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00426637202313170790466</td>\n      <td>-12</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    Patient_Week   FVC  ...                    Patient Weeks\n0  ID00419637202311204720264_-12  2000  ...  ID00419637202311204720264   -12\n1  ID00421637202311550012437_-12  2000  ...  ID00421637202311550012437   -12\n2  ID00422637202311677017371_-12  2000  ...  ID00422637202311677017371   -12\n3  ID00423637202312137826377_-12  2000  ...  ID00423637202312137826377   -12\n4  ID00426637202313170790466_-12  2000  ...  ID00426637202313170790466   -12\n\n[5 rows x 5 columns]"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# extract the Patient and weeks from the Patient_Week column\n",
    "sub_df['Patient'] = sub_df['Patient_Week'].apply(lambda x: x.split('_')[0])\n",
    "sub_df['Weeks'] = sub_df['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00419637202311204720264_-12</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-12</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00419637202311204720264_-11</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-11</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00419637202311204720264_-10</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-10</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00419637202311204720264_-9</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-9</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00419637202311204720264_-8</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-8</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    Patient_Week  Confidence  ...   Sex  SmokingStatus\n0  ID00419637202311204720264_-12         100  ...  Male      Ex-smoker\n1  ID00419637202311204720264_-11         100  ...  Male      Ex-smoker\n2  ID00419637202311204720264_-10         100  ...  Male      Ex-smoker\n3   ID00419637202311204720264_-9         100  ...  Male      Ex-smoker\n4   ID00419637202311204720264_-8         100  ...  Male      Ex-smoker\n\n[5 rows x 9 columns]"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# merge the sub_df with the test_df\n",
    "sub_df = sub_df.drop('FVC', axis=1).merge(test_df.drop('Weeks', axis=1), on='Patient')\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['FROM'] = 'train'\n",
    "test_df['FROM'] = 'val'\n",
    "sub_df['FROM'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(730, 10)"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5, 8)"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = train_df.append([test_df, sub_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize base_week column\n",
    "combined_df['Base_Week'] = combined_df['Weeks']\n",
    "# make the weeks from sub_df to be np.nan so that when we calculate the base_week it comes from the test_df\n",
    "combined_df.loc[combined_df['FROM'] == 'test', 'Base_Week'] = np.nan\n",
    "# now calculate the min for each patient group and set it to the Base_Week column\n",
    "combined_df['Base_Week'] = combined_df.groupby('Patient')['Base_Week'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the base_df (where the Base_Week == the min_week we calculated) so that we can get the base_fvc, base_age and base_percentage\n",
    "base_df = combined_df[combined_df['Weeks'] == combined_df['Base_Week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n"
    }
   ],
   "source": [
    "base_df.rename(columns={\n",
    "    'FVC': 'Base_FVC',\n",
    "    'Percent': 'Base_Percent',\n",
    "    'Age': 'Base_Age'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.merge(base_df[['Patient', 'Base_FVC', 'Base_Percent', 'Base_Age']], on='Patient', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3821</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3823</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3824</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        Patient  Weeks   FVC  ...  Base_FVC  Base_Percent Base_Age\n3821  ID00426637202313170790466    132  2925  ...      2925     71.824968       73\n3822  ID00426637202313170790466    132  2925  ...      2925     71.824968       73\n3823  ID00426637202313170790466    133  2925  ...      2925     71.824968       73\n3824  ID00426637202313170790466    133  2925  ...      2925     71.824968       73\n3825  ID00426637202313170790466    133  2925  ...      2925     71.824968       73\n\n[5 rows x 14 columns]"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Weeks_Passed'] = combined_df['Weeks'] - combined_df['Base_Week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3821</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3823</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3824</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Base_Age  Weeks_Passed\n3821  ID00426637202313170790466    132  ...        73         132.0\n3822  ID00426637202313170790466    132  ...        73         132.0\n3823  ID00426637202313170790466    133  ...        73         133.0\n3824  ID00426637202313170790466    133  ...        73         133.0\n3825  ID00426637202313170790466    133  ...        73         133.0\n\n[5 rows x 15 columns]"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MinMaxScaler(copy=True, feature_range=(0, 1))"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "MIN_MAX_SCALER.fit(combined_df[combined_df['FROM'] == 'train'][['Weeks_Passed', 'FVC', 'Percent', 'Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3821</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3823</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3824</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Base_Age  Weeks_Passed\n3821  ID00426637202313170790466    132  ...        73         132.0\n3822  ID00426637202313170790466    132  ...        73         132.0\n3823  ID00426637202313170790466    133  ...        73         133.0\n3824  ID00426637202313170790466    133  ...        73         133.0\n3825  ID00426637202313170790466    133  ...        73         133.0\n\n[5 rows x 15 columns]"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']] = MIN_MAX_SCALER.transform(combined_df[['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categoricals into dummies\n",
    "combined_df['Sex'] = pd.Categorical(combined_df['Sex'], categories=SEX_COLUMNS)\n",
    "combined_df['SmokingStatus'] = pd.Categorical(combined_df['SmokingStatus'], categories=SMOKING_STATUS_COLUMNS)\n",
    "combined_df = combined_df.join(pd.get_dummies(combined_df['Sex']))\n",
    "combined_df = combined_df.join(pd.get_dummies(combined_df['SmokingStatus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n      <th>Male</th>\n      <th>Female</th>\n      <th>Currently smokes</th>\n      <th>Ex-smoker</th>\n      <th>Never smoked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00007637202177411956430</td>\n      <td>-4</td>\n      <td>2315</td>\n      <td>58.253649</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00007637202177411956430</td>\n      <td>5</td>\n      <td>2214</td>\n      <td>55.712129</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.142857</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00007637202177411956430</td>\n      <td>7</td>\n      <td>2061</td>\n      <td>51.862104</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.174603</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00007637202177411956430</td>\n      <td>9</td>\n      <td>2144</td>\n      <td>53.950679</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.206349</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00007637202177411956430</td>\n      <td>11</td>\n      <td>2069</td>\n      <td>52.063412</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.238095</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2265</th>\n      <td>ID00426637202313170790466</td>\n      <td>129</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_129</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.047619</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2266</th>\n      <td>ID00426637202313170790466</td>\n      <td>130</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_130</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.063492</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2267</th>\n      <td>ID00426637202313170790466</td>\n      <td>131</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_131</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.079365</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2268</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.095238</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2269</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.111111</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2270 rows × 20 columns</p>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Ex-smoker  Never smoked\n0     ID00007637202177411956430     -4  ...          1             0\n1     ID00007637202177411956430      5  ...          1             0\n2     ID00007637202177411956430      7  ...          1             0\n3     ID00007637202177411956430      9  ...          1             0\n4     ID00007637202177411956430     11  ...          1             0\n...                         ...    ...  ...        ...           ...\n2265  ID00426637202313170790466    129  ...          0             1\n2266  ID00426637202313170790466    130  ...          0             1\n2267  ID00426637202313170790466    131  ...          0             1\n2268  ID00426637202313170790466    132  ...          0             1\n2269  ID00426637202313170790466    133  ...          0             1\n\n[2270 rows x 20 columns]"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "combined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PulmonaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, FV, test=False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        self.FV = FV\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.df[self.FV].iloc[idx].values),\n",
    "            'target': torch.tensor(self.df['FVC'].iloc[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PulmonaryModel(nn.Module):\n",
    "    def __init__(self, in_features=9, out_quantiles=3):\n",
    "        super(PulmonaryModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, out_quantiles)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_one, clip_two = torch.tensor(70, dtype=torch.float32).to(DEVICE), torch.tensor(1000, dtype=torch.float32).to(DEVICE)\n",
    "def score(y_true, y_pred):\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "\n",
    "    sigma_clip = torch.max(sigma, clip_one)\n",
    "    delta = torch.abs(y_true - fvc_pred)\n",
    "    delta = torch.min(delta, clip_two)\n",
    "    sq2 = torch.sqrt(torch.tensor(2, dtype=torch.float32))\n",
    "    metric = (delta / sigma_clip) * sq2 + torch.log(sigma_clip * sq2)\n",
    "    return torch.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(preds, target, quantiles, _lambda):\n",
    "    assert not target.requires_grad\n",
    "    assert preds.size(0) == target.size(0)\n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = target - preds[:, i]\n",
    "        losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(1))\n",
    "    loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "    # return loss\n",
    "    return _lambda * loss + (1 - _lambda) * score(target, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_data_loader, optimizer, train_loss):\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        features = data['features']\n",
    "        targets = data['target']\n",
    "\n",
    "        features = features.to(DEVICE).float()\n",
    "        targets = targets.to(DEVICE).float()\n",
    "\n",
    "        model.zero_grad()\n",
    "        out = model(features)\n",
    "        loss = quantile_loss(out, targets, QUANTILES, 0.6)\n",
    "        train_loss.update(loss, features.size(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(model, valid_data_loader, valid_loss, lr_scheduler):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_data_loader):\n",
    "            features = data['features']\n",
    "            targets = data['target']\n",
    "\n",
    "            features = features.to(DEVICE).float()\n",
    "            targets = targets.to(DEVICE).float()\n",
    "            \n",
    "            out = model(features)\n",
    "            loss = quantile_loss(out, targets, QUANTILES, 0.6)\n",
    "            valid_loss.update(loss, features.size(0))\n",
    "    \n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step(valid_loss.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = combined_df[combined_df['FROM'] == 'train'].reset_index(drop=True)\n",
    "TRAIN_PATIENTS = new_train_df['Patient'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0/1100, Loss 2565.88232421875\nFold 0, Valid Loss 2740.00341796875 \n\nEpoch 50/1100, Loss 444.3134765625\nFold 0, Valid Loss 444.6546936035156 \n\nEpoch 100/1100, Loss 278.2435302734375\nFold 0, Valid Loss 367.0042724609375 \n\nEpoch 150/1100, Loss 211.2231903076172\nFold 0, Valid Loss 313.4414978027344 \n\nEpoch 200/1100, Loss 178.32240295410156\nFold 0, Valid Loss 281.9181213378906 \n\nEpoch 250/1100, Loss 160.99185180664062\nFold 0, Valid Loss 262.3938903808594 \n\nEpoch 300/1100, Loss 152.3524627685547\nFold 0, Valid Loss 248.6693572998047 \n\nEpoch 350/1100, Loss 146.09017944335938\nFold 0, Valid Loss 237.56304931640625 \n\nEpoch 400/1100, Loss 140.57394409179688\nFold 0, Valid Loss 229.41932678222656 \n\nEpoch 450/1100, Loss 136.79217529296875\nFold 0, Valid Loss 225.1420440673828 \n\nEpoch 500/1100, Loss 133.68885803222656\nFold 0, Valid Loss 221.9834747314453 \n\nEpoch 550/1100, Loss 130.76727294921875\nFold 0, Valid Loss 217.43038940429688 \n\nEpoch 600/1100, Loss 127.92623138427734\nFold 0, Valid Loss 213.6257781982422 \n\nEpoch 650/1100, Loss 126.04889678955078\nFold 0, Valid Loss 211.0591583251953 \n\nEpoch 700/1100, Loss 123.9798583984375\nFold 0, Valid Loss 209.12078857421875 \n\nEpoch 750/1100, Loss 122.14569091796875\nFold 0, Valid Loss 206.5912628173828 \n\nEpoch 800/1100, Loss 120.0123062133789\nFold 0, Valid Loss 205.01687622070312 \n\nEpoch 850/1100, Loss 118.36981201171875\nFold 0, Valid Loss 203.96255493164062 \n\nEpoch 900/1100, Loss 116.93197631835938\nFold 0, Valid Loss 201.9630584716797 \n\nEpoch 950/1100, Loss 115.42666625976562\nFold 0, Valid Loss 200.2650909423828 \n\nEpoch 1000/1100, Loss 113.68721771240234\nFold 0, Valid Loss 199.2621612548828 \n\nEpoch  1041: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 1050/1100, Loss 112.28328704833984\nFold 0, Valid Loss 198.9195556640625 \n\nEpoch 0/1100, Loss 2591.060546875\nFold 1, Valid Loss 2643.54541015625 \n\nEpoch 50/1100, Loss 429.6401672363281\nFold 1, Valid Loss 501.3995666503906 \n\nEpoch 100/1100, Loss 330.75909423828125\nFold 1, Valid Loss 370.2846984863281 \n\nEpoch 150/1100, Loss 269.84930419921875\nFold 1, Valid Loss 244.71218872070312 \n\nEpoch 200/1100, Loss 220.80787658691406\nFold 1, Valid Loss 161.01071166992188 \n\nEpoch 250/1100, Loss 200.3604736328125\nFold 1, Valid Loss 141.87330627441406 \n\nEpoch 300/1100, Loss 189.78504943847656\nFold 1, Valid Loss 131.72007751464844 \n\nEpoch 350/1100, Loss 182.01365661621094\nFold 1, Valid Loss 123.77932739257812 \n\nEpoch 400/1100, Loss 177.08709716796875\nFold 1, Valid Loss 120.03007507324219 \n\nEpoch 450/1100, Loss 171.9608154296875\nFold 1, Valid Loss 117.13695526123047 \n\nEpoch 500/1100, Loss 167.32725524902344\nFold 1, Valid Loss 118.33231353759766 \n\nEpoch 550/1100, Loss 164.40921020507812\nFold 1, Valid Loss 115.86952209472656 \n\nEpoch 600/1100, Loss 161.36819458007812\nFold 1, Valid Loss 118.22465515136719 \n\nEpoch   618: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 650/1100, Loss 159.27818298339844\nFold 1, Valid Loss 118.66392517089844 \n\nEpoch   669: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 700/1100, Loss 157.84007263183594\nFold 1, Valid Loss 119.54367065429688 \n\nEpoch   720: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 750/1100, Loss 156.89891052246094\nFold 1, Valid Loss 121.18832397460938 \n\nEpoch   771: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 800/1100, Loss 156.30575561523438\nFold 1, Valid Loss 122.15343475341797 \n\nEpoch   822: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 850/1100, Loss 155.8411865234375\nFold 1, Valid Loss 121.00675201416016 \n\nEpoch   873: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 900/1100, Loss 155.46449279785156\nFold 1, Valid Loss 121.62156677246094 \n\nEpoch   924: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 950/1100, Loss 155.28311157226562\nFold 1, Valid Loss 121.8416976928711 \n\nEpoch   975: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 1000/1100, Loss 155.10557556152344\nFold 1, Valid Loss 121.0310287475586 \n\nEpoch  1026: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 1050/1100, Loss 154.9942169189453\nFold 1, Valid Loss 121.15496826171875 \n\nEpoch  1077: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 0/1100, Loss 2720.7802734375\nFold 2, Valid Loss 2121.19775390625 \n\nEpoch 50/1100, Loss 428.6873474121094\nFold 2, Valid Loss 341.2706604003906 \n\nEpoch 100/1100, Loss 314.65118408203125\nFold 2, Valid Loss 187.2074737548828 \n\nEpoch 150/1100, Loss 254.4912109375\nFold 2, Valid Loss 113.00300598144531 \n\nEpoch 200/1100, Loss 214.802734375\nFold 2, Valid Loss 106.97328186035156 \n\nEpoch   234: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 250/1100, Loss 188.65000915527344\nFold 2, Valid Loss 141.4066925048828 \n\nEpoch   285: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 300/1100, Loss 176.9694366455078\nFold 2, Valid Loss 148.84896850585938 \n\nEpoch   336: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 350/1100, Loss 171.20111083984375\nFold 2, Valid Loss 161.6139373779297 \n\nEpoch   387: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 400/1100, Loss 167.4966278076172\nFold 2, Valid Loss 165.99386596679688 \n\nEpoch   438: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 450/1100, Loss 165.49755859375\nFold 2, Valid Loss 171.01502990722656 \n\nEpoch   489: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 500/1100, Loss 164.14706420898438\nFold 2, Valid Loss 174.36390686035156 \n\nEpoch   540: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 550/1100, Loss 163.30226135253906\nFold 2, Valid Loss 175.162109375 \n\nEpoch   591: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 600/1100, Loss 162.75662231445312\nFold 2, Valid Loss 175.25172424316406 \n\nEpoch   642: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 650/1100, Loss 162.37254333496094\nFold 2, Valid Loss 175.19735717773438 \n\nEpoch   693: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 700/1100, Loss 162.17269897460938\nFold 2, Valid Loss 175.9786834716797 \n\nEpoch   744: reducing learning rate of group 0 to 9.8866e-06.\nEpoch 750/1100, Loss 161.9486541748047\nFold 2, Valid Loss 175.53753662109375 \n\nEpoch   795: reducing learning rate of group 0 to 6.9206e-06.\nEpoch 800/1100, Loss 161.82179260253906\nFold 2, Valid Loss 175.7490692138672 \n\nEpoch   846: reducing learning rate of group 0 to 4.8445e-06.\nEpoch 850/1100, Loss 161.74815368652344\nFold 2, Valid Loss 175.669677734375 \n\nEpoch   897: reducing learning rate of group 0 to 3.3911e-06.\nEpoch 900/1100, Loss 161.6985626220703\nFold 2, Valid Loss 175.8231201171875 \n\nEpoch   948: reducing learning rate of group 0 to 2.3738e-06.\nEpoch 950/1100, Loss 161.6567840576172\nFold 2, Valid Loss 175.85940551757812 \n\nEpoch   999: reducing learning rate of group 0 to 1.6616e-06.\nEpoch 1000/1100, Loss 161.62892150878906\nFold 2, Valid Loss 175.93141174316406 \n\nEpoch  1050: reducing learning rate of group 0 to 1.1632e-06.\nEpoch 1050/1100, Loss 161.61007690429688\nFold 2, Valid Loss 175.92575073242188 \n\nEpoch 0/1100, Loss 2549.466796875\nFold 3, Valid Loss 2810.951416015625 \n\nEpoch 50/1100, Loss 427.6512451171875\nFold 3, Valid Loss 495.3551940917969 \n\nEpoch 100/1100, Loss 261.12689208984375\nFold 3, Valid Loss 475.8070373535156 \n\nEpoch 150/1100, Loss 198.54281616210938\nFold 3, Valid Loss 421.6782531738281 \n\nEpoch 200/1100, Loss 179.9184112548828\nFold 3, Valid Loss 380.72222900390625 \n\nEpoch 250/1100, Loss 173.06192016601562\nFold 3, Valid Loss 355.3697509765625 \n\nEpoch 300/1100, Loss 169.50466918945312\nFold 3, Valid Loss 325.1339111328125 \n\nEpoch 350/1100, Loss 165.05145263671875\nFold 3, Valid Loss 292.883544921875 \n\nEpoch 400/1100, Loss 162.2952423095703\nFold 3, Valid Loss 270.9408264160156 \n\nEpoch 450/1100, Loss 159.70681762695312\nFold 3, Valid Loss 251.20437622070312 \n\nEpoch 500/1100, Loss 157.38162231445312\nFold 3, Valid Loss 236.09600830078125 \n\nEpoch 550/1100, Loss 155.6311492919922\nFold 3, Valid Loss 227.014404296875 \n\nEpoch 600/1100, Loss 153.7809295654297\nFold 3, Valid Loss 217.60317993164062 \n\nEpoch 650/1100, Loss 151.57135009765625\nFold 3, Valid Loss 205.85751342773438 \n\nEpoch 700/1100, Loss 151.56179809570312\nFold 3, Valid Loss 198.05084228515625 \n\nEpoch 750/1100, Loss 148.1696319580078\nFold 3, Valid Loss 191.56687927246094 \n\nEpoch 800/1100, Loss 146.49082946777344\nFold 3, Valid Loss 182.68556213378906 \n\nEpoch 850/1100, Loss 145.12493896484375\nFold 3, Valid Loss 177.3773193359375 \n\nEpoch 900/1100, Loss 143.67471313476562\nFold 3, Valid Loss 173.01425170898438 \n\nEpoch 950/1100, Loss 141.80706787109375\nFold 3, Valid Loss 168.13951110839844 \n\nEpoch 1000/1100, Loss 140.14178466796875\nFold 3, Valid Loss 163.1315155029297 \n\nEpoch 1050/1100, Loss 138.55572509765625\nFold 3, Valid Loss 158.77650451660156 \n\nEpoch 0/1100, Loss 2580.150390625\nFold 4, Valid Loss 2687.3486328125 \n\nEpoch 50/1100, Loss 441.13592529296875\nFold 4, Valid Loss 480.5647888183594 \n\nEpoch 100/1100, Loss 310.87078857421875\nFold 4, Valid Loss 326.8063049316406 \n\nEpoch 150/1100, Loss 241.90975952148438\nFold 4, Valid Loss 235.94151306152344 \n\nEpoch 200/1100, Loss 208.8005828857422\nFold 4, Valid Loss 198.13389587402344 \n\nEpoch 250/1100, Loss 190.0787353515625\nFold 4, Valid Loss 188.7050323486328 \n\nEpoch 300/1100, Loss 175.79498291015625\nFold 4, Valid Loss 183.00393676757812 \n\nEpoch   344: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 350/1100, Loss 166.5669708251953\nFold 4, Valid Loss 188.02316284179688 \n\nEpoch   395: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 400/1100, Loss 160.857177734375\nFold 4, Valid Loss 195.0284423828125 \n\nEpoch   446: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 450/1100, Loss 157.50050354003906\nFold 4, Valid Loss 197.17050170898438 \n\nEpoch   497: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 500/1100, Loss 155.50210571289062\nFold 4, Valid Loss 197.55877685546875 \n\nEpoch   548: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 550/1100, Loss 154.10269165039062\nFold 4, Valid Loss 198.54925537109375 \n\nEpoch   599: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 600/1100, Loss 153.35755920410156\nFold 4, Valid Loss 199.52737426757812 \n\nEpoch   650: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 650/1100, Loss 152.66921997070312\nFold 4, Valid Loss 200.35745239257812 \n\nEpoch   701: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 700/1100, Loss 152.0537109375\nFold 4, Valid Loss 202.33172607421875 \n\nEpoch 750/1100, Loss 151.67095947265625\nFold 4, Valid Loss 201.77479553222656 \n\nEpoch   752: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 800/1100, Loss 151.41966247558594\nFold 4, Valid Loss 202.02923583984375 \n\nEpoch   803: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 850/1100, Loss 151.24317932128906\nFold 4, Valid Loss 202.3997802734375 \n\nEpoch   854: reducing learning rate of group 0 to 9.8866e-06.\nEpoch 900/1100, Loss 151.12835693359375\nFold 4, Valid Loss 202.52268981933594 \n\nEpoch   905: reducing learning rate of group 0 to 6.9206e-06.\nEpoch 950/1100, Loss 151.05841064453125\nFold 4, Valid Loss 202.77545166015625 \n\nEpoch   956: reducing learning rate of group 0 to 4.8445e-06.\nEpoch 1000/1100, Loss 150.98751831054688\nFold 4, Valid Loss 202.68150329589844 \n\nEpoch  1007: reducing learning rate of group 0 to 3.3911e-06.\nEpoch 1050/1100, Loss 150.9388885498047\nFold 4, Valid Loss 202.51588439941406 \n\nEpoch  1058: reducing learning rate of group 0 to 2.3738e-06.\n"
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kf.split(TRAIN_PATIENTS)):\n",
    "    model = PulmonaryModel(len(FV))\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    df_train = new_train_df.iloc[train_index].reset_index(drop=True)\n",
    "    df_valid = new_train_df.iloc[test_index].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = PulmonaryDataset(df_train, FV)\n",
    "    valid_dataset = PulmonaryDataset(df_valid, FV)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=10,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=50, factor=0.7, verbose=True)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    \n",
    "    # tq = tqdm(range(NUM_EPOCHS), desc=f\"Fold {fold}\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = AverageMeter()\n",
    "        valid_loss = AverageMeter()\n",
    "\n",
    "        train_one_epoch(model, train_data_loader, optimizer, train_loss)\n",
    "        eval_one_epoch(model, valid_data_loader, valid_loss, lr_scheduler)\n",
    "\n",
    "        if epoch % PRINT_EVERY == 0:\n",
    "            print(f\"Epoch {epoch}/{NUM_EPOCHS}, Loss {train_loss.avg}\")\n",
    "            print(f\"Fold {fold}, Valid Loss {valid_loss.avg} \\n\")\n",
    "        \n",
    "        # tq.set_postfix(val_loss=valid_loss.avg.item())\n",
    "\n",
    "        if valid_loss.avg < best_valid_loss:\n",
    "            best_valid_loss = valid_loss.avg\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, os.path.join(CONFIG.CFG.DATA.MODELS_OUT, f\"model_fold_{fold}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.upload_to_kaggle(\"osicqrmodel\", \"OSIC QR Model\", new=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for fold in range(K_FOLDS):\n",
    "    model = PulmonaryModel(len(FV))\n",
    "    model = model.to(DEVICE)\n",
    "    checkpoint = torch.load(os.path.join(CONFIG.CFG.DATA.MODELS_OUT, f\"model_fold_{fold}.pt\"))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = combined_df[combined_df['FROM'] == 'test'].reset_index(drop=True)\n",
    "test_dataset = PulmonaryDataset(new_test_df, FV)\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(730, 20)"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "new_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_preds = np.zeros((len(test_dataset), len(QUANTILES)))\n",
    "with torch.no_grad():\n",
    "    for model in models:\n",
    "        preds = []\n",
    "        for j, test_data in enumerate(test_data_loader):\n",
    "            features = test_data['features']\n",
    "            targets = test_data['target']\n",
    "\n",
    "            features = features.to(DEVICE).float()\n",
    "            targets = targets.to(DEVICE).float()\n",
    "\n",
    "            out = model(features)\n",
    "            preds.append(out)\n",
    "        preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "        avg_preds += preds\n",
    "avg_preds /= len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2898.08457031, 3142.53564453, 3377.50253906],\n       [2892.51005859, 3136.5050293 , 3371.03310547],\n       [2886.93530273, 3130.47456055, 3364.56391602],\n       ...,\n       [2028.98952637, 2202.49018555, 2369.36118164],\n       [2023.7012207 , 2196.76708984, 2363.21899414],\n       [2018.41291504, 2191.04406738, 2357.07675781]])"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(730, 10)"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = new_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['FVC'] = avg_preds[:, 1]\n",
    "temp_df['Confidence'] = np.abs(avg_preds[:, 2] - avg_preds[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv(\"view.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inverse the scaling operation for FVC\n",
    "# avg_preds -= MIN_MAX_SCALER.min_[SCALE_COLUMNS.index('FVC')]\n",
    "# avg_preds /= MIN_MAX_SCALER.scale_[SCALE_COLUMNS.index('FVC')]"
   ]
  }
 ]
}