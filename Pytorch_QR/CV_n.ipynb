{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath(os.pardir) not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath(os.pardir))\n",
    "import CONFIG\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CONFIG.CFG.DATA.BASE\n",
    "K_FOLDS = 5\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-4\n",
    "NUM_EPOCHS = 1100\n",
    "# print loss every\n",
    "PRINT_EVERY = 50\n",
    "\n",
    "QUANTILES = [0.2, 0.5, 0.8]\n",
    "SCALE_COLUMNS = ['Weeks', 'FVC', 'Percent', 'Age'] #'Percent'\n",
    "SCALE_COLUMNS = ['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']\n",
    "SEX_COLUMNS = ['Male', 'Female']\n",
    "SMOKING_STATUS_COLUMNS = ['Currently smokes', 'Ex-smoker', 'Never smoked']\n",
    "FV = SEX_COLUMNS + SMOKING_STATUS_COLUMNS + SCALE_COLUMNS\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.KFold(K_FOLDS)\n",
    "MIN_MAX_SCALER = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "sub_df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "# remove the duplicates from the train_df\n",
    "train_df.drop_duplicates(keep=False, inplace=True, subset=['Patient', 'Weeks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_Week</th>\n      <th>FVC</th>\n      <th>Confidence</th>\n      <th>Patient</th>\n      <th>Weeks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00419637202311204720264_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00421637202311550012437_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00421637202311550012437</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00422637202311677017371_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00422637202311677017371</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00423637202312137826377_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00423637202312137826377</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00426637202313170790466_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00426637202313170790466</td>\n      <td>-12</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    Patient_Week   FVC  ...                    Patient Weeks\n0  ID00419637202311204720264_-12  2000  ...  ID00419637202311204720264   -12\n1  ID00421637202311550012437_-12  2000  ...  ID00421637202311550012437   -12\n2  ID00422637202311677017371_-12  2000  ...  ID00422637202311677017371   -12\n3  ID00423637202312137826377_-12  2000  ...  ID00423637202312137826377   -12\n4  ID00426637202313170790466_-12  2000  ...  ID00426637202313170790466   -12\n\n[5 rows x 5 columns]"
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "# extract the Patient and weeks from the Patient_Week column\n",
    "sub_df['Patient'] = sub_df['Patient_Week'].apply(lambda x: x.split('_')[0])\n",
    "sub_df['Weeks'] = sub_df['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00419637202311204720264_-12</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-12</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00419637202311204720264_-11</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-11</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00419637202311204720264_-10</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-10</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00419637202311204720264_-9</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-9</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00419637202311204720264_-8</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-8</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    Patient_Week  Confidence  ...   Sex  SmokingStatus\n0  ID00419637202311204720264_-12         100  ...  Male      Ex-smoker\n1  ID00419637202311204720264_-11         100  ...  Male      Ex-smoker\n2  ID00419637202311204720264_-10         100  ...  Male      Ex-smoker\n3   ID00419637202311204720264_-9         100  ...  Male      Ex-smoker\n4   ID00419637202311204720264_-8         100  ...  Male      Ex-smoker\n\n[5 rows x 9 columns]"
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "# merge the sub_df with the test_df\n",
    "sub_df = sub_df.drop('FVC', axis=1).merge(test_df.drop('Weeks', axis=1), on='Patient')\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['FROM'] = 'train'\n",
    "test_df['FROM'] = 'val'\n",
    "sub_df['FROM'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(730, 10)"
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5, 8)"
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = train_df.append([test_df, sub_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize base_week column\n",
    "combined_df['Base_Week'] = combined_df['Weeks']\n",
    "# make the weeks from sub_df to be np.nan so that when we calculate the base_week it comes from the test_df\n",
    "combined_df.loc[combined_df['FROM'] == 'test', 'Base_Week'] = np.nan\n",
    "# now calculate the min for each patient group and set it to the Base_Week column\n",
    "combined_df['Base_Week'] = combined_df.groupby('Patient')['Base_Week'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the base_df (where the Base_Week == the min_week we calculated) so that we can get the base_fvc, base_age and base_percentage\n",
    "base_df = combined_df[combined_df['Weeks'] == combined_df['Base_Week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n"
    }
   ],
   "source": [
    "base_df.rename(columns={\n",
    "    'FVC': 'Base_FVC',\n",
    "    'Percent': 'Base_Percent',\n",
    "    'Age': 'Base_Age'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.merge(base_df[['Patient', 'Base_FVC', 'Base_Percent', 'Base_Age']], on='Patient', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3821</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3823</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3824</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        Patient  Weeks   FVC  ...  Base_FVC  Base_Percent Base_Age\n3821  ID00426637202313170790466    132  2925  ...      2925     71.824968       73\n3822  ID00426637202313170790466    132  2925  ...      2925     71.824968       73\n3823  ID00426637202313170790466    133  2925  ...      2925     71.824968       73\n3824  ID00426637202313170790466    133  2925  ...      2925     71.824968       73\n3825  ID00426637202313170790466    133  2925  ...      2925     71.824968       73\n\n[5 rows x 14 columns]"
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Weeks_Passed'] = combined_df['Weeks'] - combined_df['Base_Week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3821</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3823</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3824</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Base_Age  Weeks_Passed\n3821  ID00426637202313170790466    132  ...        73         132.0\n3822  ID00426637202313170790466    132  ...        73         132.0\n3823  ID00426637202313170790466    133  ...        73         133.0\n3824  ID00426637202313170790466    133  ...        73         133.0\n3825  ID00426637202313170790466    133  ...        73         133.0\n\n[5 rows x 15 columns]"
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MinMaxScaler(copy=True, feature_range=(0, 1))"
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "MIN_MAX_SCALER.fit(combined_df[combined_df['FROM'] == 'train'][['Weeks_Passed', 'FVC', 'Percent', 'Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3821</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3823</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3824</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Base_Age  Weeks_Passed\n3821  ID00426637202313170790466    132  ...        73         132.0\n3822  ID00426637202313170790466    132  ...        73         132.0\n3823  ID00426637202313170790466    133  ...        73         133.0\n3824  ID00426637202313170790466    133  ...        73         133.0\n3825  ID00426637202313170790466    133  ...        73         133.0\n\n[5 rows x 15 columns]"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']] = MIN_MAX_SCALER.transform(combined_df[['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categoricals into dummies\n",
    "combined_df['Sex'] = pd.Categorical(combined_df['Sex'], categories=SEX_COLUMNS)\n",
    "combined_df['SmokingStatus'] = pd.Categorical(combined_df['SmokingStatus'], categories=SMOKING_STATUS_COLUMNS)\n",
    "combined_df = combined_df.join(pd.get_dummies(combined_df['Sex']))\n",
    "combined_df = combined_df.join(pd.get_dummies(combined_df['SmokingStatus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n      <th>Male</th>\n      <th>Female</th>\n      <th>Currently smokes</th>\n      <th>Ex-smoker</th>\n      <th>Never smoked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00007637202177411956430</td>\n      <td>-4</td>\n      <td>2315</td>\n      <td>58.253649</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00007637202177411956430</td>\n      <td>5</td>\n      <td>2214</td>\n      <td>55.712129</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.142857</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00007637202177411956430</td>\n      <td>7</td>\n      <td>2061</td>\n      <td>51.862104</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.174603</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00007637202177411956430</td>\n      <td>9</td>\n      <td>2144</td>\n      <td>53.950679</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.206349</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00007637202177411956430</td>\n      <td>11</td>\n      <td>2069</td>\n      <td>52.063412</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.238095</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2265</th>\n      <td>ID00426637202313170790466</td>\n      <td>129</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_129</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.047619</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2266</th>\n      <td>ID00426637202313170790466</td>\n      <td>130</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_130</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.063492</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2267</th>\n      <td>ID00426637202313170790466</td>\n      <td>131</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_131</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.079365</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2268</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.095238</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2269</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.111111</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2270 rows Ã— 20 columns</p>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Ex-smoker  Never smoked\n0     ID00007637202177411956430     -4  ...          1             0\n1     ID00007637202177411956430      5  ...          1             0\n2     ID00007637202177411956430      7  ...          1             0\n3     ID00007637202177411956430      9  ...          1             0\n4     ID00007637202177411956430     11  ...          1             0\n...                         ...    ...  ...        ...           ...\n2265  ID00426637202313170790466    129  ...          0             1\n2266  ID00426637202313170790466    130  ...          0             1\n2267  ID00426637202313170790466    131  ...          0             1\n2268  ID00426637202313170790466    132  ...          0             1\n2269  ID00426637202313170790466    133  ...          0             1\n\n[2270 rows x 20 columns]"
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "combined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PulmonaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, FV, test=False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        self.FV = FV\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.df[self.FV].iloc[idx].values),\n",
    "            'target': torch.tensor(self.df['FVC'].iloc[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PulmonaryModel(nn.Module):\n",
    "    def __init__(self, in_features=9, out_quantiles=3):\n",
    "        super(PulmonaryModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, out_quantiles)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_one, clip_two = torch.tensor(70, dtype=torch.float32).to(DEVICE), torch.tensor(1000, dtype=torch.float32).to(DEVICE)\n",
    "def score(y_true, y_pred):\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "\n",
    "    sigma_clip = torch.max(sigma, clip_one)\n",
    "    delta = torch.abs(y_true - fvc_pred)\n",
    "    delta = torch.min(delta, clip_two)\n",
    "    sq2 = torch.sqrt(torch.tensor(2, dtype=torch.float32))\n",
    "    metric = (delta / sigma_clip) * sq2 + torch.log(sigma_clip * sq2)\n",
    "    return torch.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(preds, target, quantiles, _lambda):\n",
    "    assert not target.requires_grad\n",
    "    assert preds.size(0) == target.size(0)\n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = target - preds[:, i]\n",
    "        losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(1))\n",
    "    loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "    # return loss\n",
    "    return _lambda * loss + (1 - _lambda) * score(target, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_data_loader, optimizer, train_loss):\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        features = data['features']\n",
    "        targets = data['target']\n",
    "\n",
    "        features = features.to(DEVICE).float()\n",
    "        targets = targets.to(DEVICE).float()\n",
    "\n",
    "        model.zero_grad()\n",
    "        out = model(features)\n",
    "        loss = quantile_loss(out, targets, QUANTILES, 0.8)\n",
    "        train_loss.update(loss, features.size(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(model, valid_data_loader, valid_loss, lr_scheduler):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_data_loader):\n",
    "            features = data['features']\n",
    "            targets = data['target']\n",
    "\n",
    "            features = features.to(DEVICE).float()\n",
    "            targets = targets.to(DEVICE).float()\n",
    "            \n",
    "            out = model(features)\n",
    "            loss = quantile_loss(out, targets, QUANTILES, 0.8)\n",
    "            valid_loss.update(loss, features.size(0))\n",
    "    \n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step(valid_loss.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = combined_df[combined_df['FROM'] == 'train'].reset_index(drop=True)\n",
    "TRAIN_PATIENTS = new_train_df['Patient'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0/1100, Loss 3412.908447265625\nFold 0, Valid Loss 3645.0712890625 \n\nEpoch 50/1100, Loss 523.5621337890625\nFold 0, Valid Loss 499.52630615234375 \n\nEpoch 100/1100, Loss 336.97406005859375\nFold 0, Valid Loss 436.2543029785156 \n\nEpoch 150/1100, Loss 250.77784729003906\nFold 0, Valid Loss 377.6388854980469 \n\nEpoch 200/1100, Loss 212.69961547851562\nFold 0, Valid Loss 339.52288818359375 \n\nEpoch 250/1100, Loss 188.67098999023438\nFold 0, Valid Loss 311.8796691894531 \n\nEpoch 300/1100, Loss 176.89234924316406\nFold 0, Valid Loss 290.4786682128906 \n\nEpoch 350/1100, Loss 168.71542358398438\nFold 0, Valid Loss 272.6313781738281 \n\nEpoch 400/1100, Loss 161.38421630859375\nFold 0, Valid Loss 263.6256408691406 \n\nEpoch 450/1100, Loss 156.77923583984375\nFold 0, Valid Loss 257.1876220703125 \n\nEpoch 500/1100, Loss 153.37620544433594\nFold 0, Valid Loss 252.1453399658203 \n\nEpoch 550/1100, Loss 149.85556030273438\nFold 0, Valid Loss 249.04139709472656 \n\nEpoch 600/1100, Loss 146.71820068359375\nFold 0, Valid Loss 245.5223846435547 \n\nEpoch 650/1100, Loss 144.39369201660156\nFold 0, Valid Loss 243.10853576660156 \n\nEpoch 700/1100, Loss 141.86422729492188\nFold 0, Valid Loss 241.5181427001953 \n\nEpoch 750/1100, Loss 139.4373321533203\nFold 0, Valid Loss 240.00027465820312 \n\nEpoch   784: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 800/1100, Loss 137.2845001220703\nFold 0, Valid Loss 239.3170623779297 \n\nEpoch 850/1100, Loss 136.22390747070312\nFold 0, Valid Loss 238.11729431152344 \n\nEpoch 900/1100, Loss 134.75607299804688\nFold 0, Valid Loss 237.13804626464844 \n\nEpoch 950/1100, Loss 134.15870666503906\nFold 0, Valid Loss 235.6083526611328 \n\nEpoch 1000/1100, Loss 132.7769775390625\nFold 0, Valid Loss 235.64840698242188 \n\nEpoch 1050/1100, Loss 131.49302673339844\nFold 0, Valid Loss 234.82798767089844 \n\nEpoch 0/1100, Loss 3446.470703125\nFold 1, Valid Loss 3516.440185546875 \n\nEpoch 50/1100, Loss 530.365966796875\nFold 1, Valid Loss 610.0975341796875 \n\nEpoch 100/1100, Loss 400.959228515625\nFold 1, Valid Loss 457.6700439453125 \n\nEpoch 150/1100, Loss 334.53125\nFold 1, Valid Loss 316.14678955078125 \n\nEpoch 200/1100, Loss 274.48492431640625\nFold 1, Valid Loss 210.8952178955078 \n\nEpoch 250/1100, Loss 242.32814025878906\nFold 1, Valid Loss 176.40760803222656 \n\nEpoch 300/1100, Loss 223.77284240722656\nFold 1, Valid Loss 158.74856567382812 \n\nEpoch 350/1100, Loss 214.0480194091797\nFold 1, Valid Loss 147.194580078125 \n\nEpoch 400/1100, Loss 206.85682678222656\nFold 1, Valid Loss 140.26292419433594 \n\nEpoch 450/1100, Loss 200.9765167236328\nFold 1, Valid Loss 133.3804931640625 \n\nEpoch 500/1100, Loss 196.7042236328125\nFold 1, Valid Loss 134.06007385253906 \n\nEpoch 550/1100, Loss 192.95098876953125\nFold 1, Valid Loss 129.68743896484375 \n\nEpoch   585: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 600/1100, Loss 189.75440979003906\nFold 1, Valid Loss 131.97061157226562 \n\nEpoch 650/1100, Loss 187.4756317138672\nFold 1, Valid Loss 131.90818786621094 \n\nEpoch   659: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 700/1100, Loss 186.23631286621094\nFold 1, Valid Loss 133.79904174804688 \n\nEpoch   710: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 750/1100, Loss 185.45838928222656\nFold 1, Valid Loss 135.25498962402344 \n\nEpoch   761: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 800/1100, Loss 184.785888671875\nFold 1, Valid Loss 135.04794311523438 \n\nEpoch   812: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 850/1100, Loss 184.28182983398438\nFold 1, Valid Loss 134.66464233398438 \n\nEpoch   863: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 900/1100, Loss 183.97604370117188\nFold 1, Valid Loss 135.25572204589844 \n\nEpoch   914: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 950/1100, Loss 183.7606964111328\nFold 1, Valid Loss 135.43701171875 \n\nEpoch   965: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 1000/1100, Loss 183.61790466308594\nFold 1, Valid Loss 135.18116760253906 \n\nEpoch  1016: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 1050/1100, Loss 183.52085876464844\nFold 1, Valid Loss 135.13507080078125 \n\nEpoch  1067: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 0/1100, Loss 3619.41455078125\nFold 2, Valid Loss 2819.960205078125 \n\nEpoch 50/1100, Loss 493.9700622558594\nFold 2, Valid Loss 395.2291259765625 \n\nEpoch 100/1100, Loss 376.7923278808594\nFold 2, Valid Loss 239.135498046875 \n\nEpoch 150/1100, Loss 301.22283935546875\nFold 2, Valid Loss 147.08343505859375 \n\nEpoch 200/1100, Loss 253.34254455566406\nFold 2, Valid Loss 128.00633239746094 \n\nEpoch   246: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 250/1100, Loss 219.260986328125\nFold 2, Valid Loss 161.62754821777344 \n\nEpoch   297: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 300/1100, Loss 202.65402221679688\nFold 2, Valid Loss 179.61886596679688 \n\nEpoch   348: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 350/1100, Loss 194.2516632080078\nFold 2, Valid Loss 200.09408569335938 \n\nEpoch   399: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 400/1100, Loss 189.31727600097656\nFold 2, Valid Loss 207.6501922607422 \n\nEpoch   450: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 450/1100, Loss 186.8463134765625\nFold 2, Valid Loss 212.155029296875 \n\nEpoch   501: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 500/1100, Loss 185.28619384765625\nFold 2, Valid Loss 215.27609252929688 \n\nEpoch 550/1100, Loss 184.09820556640625\nFold 2, Valid Loss 217.15228271484375 \n\nEpoch   552: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 600/1100, Loss 183.53697204589844\nFold 2, Valid Loss 218.53086853027344 \n\nEpoch   603: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 650/1100, Loss 183.12057495117188\nFold 2, Valid Loss 218.92108154296875 \n\nEpoch   654: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 700/1100, Loss 182.93800354003906\nFold 2, Valid Loss 219.93304443359375 \n\nEpoch   705: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 750/1100, Loss 182.6971893310547\nFold 2, Valid Loss 219.1085968017578 \n\nEpoch   756: reducing learning rate of group 0 to 9.8866e-06.\nEpoch 800/1100, Loss 182.5628662109375\nFold 2, Valid Loss 219.3041534423828 \n\nEpoch   807: reducing learning rate of group 0 to 6.9206e-06.\nEpoch 850/1100, Loss 182.47146606445312\nFold 2, Valid Loss 219.21812438964844 \n\nEpoch   858: reducing learning rate of group 0 to 4.8445e-06.\nEpoch 900/1100, Loss 182.4263916015625\nFold 2, Valid Loss 219.47213745117188 \n\nEpoch   909: reducing learning rate of group 0 to 3.3911e-06.\nEpoch 950/1100, Loss 182.379150390625\nFold 2, Valid Loss 219.52734375 \n\nEpoch   960: reducing learning rate of group 0 to 2.3738e-06.\nEpoch 1000/1100, Loss 182.34622192382812\nFold 2, Valid Loss 219.591552734375 \n\nEpoch  1011: reducing learning rate of group 0 to 1.6616e-06.\nEpoch 1050/1100, Loss 182.32785034179688\nFold 2, Valid Loss 219.56549072265625 \n\nEpoch  1062: reducing learning rate of group 0 to 1.1632e-06.\nEpoch 0/1100, Loss 3391.012939453125\nFold 3, Valid Loss 3739.649658203125 \n\nEpoch 50/1100, Loss 486.3674621582031\nFold 3, Valid Loss 607.807373046875 \n\nEpoch 100/1100, Loss 324.4873962402344\nFold 3, Valid Loss 532.2759399414062 \n\nEpoch 150/1100, Loss 237.43505859375\nFold 3, Valid Loss 499.70721435546875 \n\nEpoch 200/1100, Loss 213.61282348632812\nFold 3, Valid Loss 443.86407470703125 \n\nEpoch 250/1100, Loss 204.38006591796875\nFold 3, Valid Loss 407.03778076171875 \n\nEpoch 300/1100, Loss 198.3607177734375\nFold 3, Valid Loss 358.43975830078125 \n\nEpoch 350/1100, Loss 192.9014434814453\nFold 3, Valid Loss 324.89520263671875 \n\nEpoch 400/1100, Loss 189.3462677001953\nFold 3, Valid Loss 302.528564453125 \n\nEpoch 450/1100, Loss 186.1339874267578\nFold 3, Valid Loss 281.33807373046875 \n\nEpoch 500/1100, Loss 182.606201171875\nFold 3, Valid Loss 258.5098876953125 \n\nEpoch 550/1100, Loss 179.7940673828125\nFold 3, Valid Loss 246.18133544921875 \n\nEpoch 600/1100, Loss 177.48825073242188\nFold 3, Valid Loss 234.16883850097656 \n\nEpoch 650/1100, Loss 175.24166870117188\nFold 3, Valid Loss 224.09104919433594 \n\nEpoch 700/1100, Loss 174.91307067871094\nFold 3, Valid Loss 215.77442932128906 \n\nEpoch 750/1100, Loss 171.19894409179688\nFold 3, Valid Loss 209.049072265625 \n\nEpoch 800/1100, Loss 169.44140625\nFold 3, Valid Loss 200.27610778808594 \n\nEpoch 850/1100, Loss 167.14353942871094\nFold 3, Valid Loss 193.8531036376953 \n\nEpoch 900/1100, Loss 165.52635192871094\nFold 3, Valid Loss 188.8826141357422 \n\nEpoch 950/1100, Loss 163.6009979248047\nFold 3, Valid Loss 184.4144744873047 \n\nEpoch 1000/1100, Loss 161.9331512451172\nFold 3, Valid Loss 179.10214233398438 \n\nEpoch 1050/1100, Loss 159.9231414794922\nFold 3, Valid Loss 174.44480895996094 \n\nEpoch 0/1100, Loss 3431.9365234375\nFold 4, Valid Loss 3574.8603515625 \n\nEpoch 50/1100, Loss 519.6202392578125\nFold 4, Valid Loss 549.2731323242188 \n\nEpoch 100/1100, Loss 382.68170166015625\nFold 4, Valid Loss 371.1275634765625 \n\nEpoch 150/1100, Loss 290.8351135253906\nFold 4, Valid Loss 271.243408203125 \n\nEpoch 200/1100, Loss 246.3603973388672\nFold 4, Valid Loss 231.58013916015625 \n\nEpoch 250/1100, Loss 222.59986877441406\nFold 4, Valid Loss 218.11695861816406 \n\nEpoch 300/1100, Loss 203.92355346679688\nFold 4, Valid Loss 215.79388427734375 \n\nEpoch   344: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 350/1100, Loss 191.94374084472656\nFold 4, Valid Loss 226.70106506347656 \n\nEpoch   395: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 400/1100, Loss 184.69766235351562\nFold 4, Valid Loss 234.84169006347656 \n\nEpoch   446: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 450/1100, Loss 180.9894561767578\nFold 4, Valid Loss 238.58856201171875 \n\nEpoch   497: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 500/1100, Loss 178.82852172851562\nFold 4, Valid Loss 236.8830108642578 \n\nEpoch   548: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 550/1100, Loss 177.0477752685547\nFold 4, Valid Loss 237.03150939941406 \n\nEpoch   599: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 600/1100, Loss 175.85137939453125\nFold 4, Valid Loss 238.70346069335938 \n\nEpoch   650: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 650/1100, Loss 175.11460876464844\nFold 4, Valid Loss 238.70921325683594 \n\nEpoch   701: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 700/1100, Loss 174.3468475341797\nFold 4, Valid Loss 241.09791564941406 \n\nEpoch 750/1100, Loss 173.89138793945312\nFold 4, Valid Loss 240.65032958984375 \n\nEpoch   752: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 800/1100, Loss 173.5579833984375\nFold 4, Valid Loss 240.7163543701172 \n\nEpoch   803: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 850/1100, Loss 173.331787109375\nFold 4, Valid Loss 241.01612854003906 \n\nEpoch   854: reducing learning rate of group 0 to 9.8866e-06.\nEpoch 900/1100, Loss 173.1715850830078\nFold 4, Valid Loss 240.90066528320312 \n\nEpoch   905: reducing learning rate of group 0 to 6.9206e-06.\nEpoch 950/1100, Loss 173.0690155029297\nFold 4, Valid Loss 241.07904052734375 \n\nEpoch   956: reducing learning rate of group 0 to 4.8445e-06.\nEpoch 1000/1100, Loss 172.98544311523438\nFold 4, Valid Loss 241.09042358398438 \n\nEpoch  1007: reducing learning rate of group 0 to 3.3911e-06.\nEpoch 1050/1100, Loss 172.9311981201172\nFold 4, Valid Loss 240.97494506835938 \n\nEpoch  1058: reducing learning rate of group 0 to 2.3738e-06.\n"
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kf.split(TRAIN_PATIENTS)):\n",
    "    model = PulmonaryModel(len(FV))\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    df_train = new_train_df.iloc[train_index].reset_index(drop=True)\n",
    "    df_valid = new_train_df.iloc[test_index].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = PulmonaryDataset(df_train, FV)\n",
    "    valid_dataset = PulmonaryDataset(df_valid, FV)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=10,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=50, factor=0.7, verbose=True)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    \n",
    "    # tq = tqdm(range(NUM_EPOCHS), desc=f\"Fold {fold}\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = AverageMeter()\n",
    "        valid_loss = AverageMeter()\n",
    "\n",
    "        train_one_epoch(model, train_data_loader, optimizer, train_loss)\n",
    "        eval_one_epoch(model, valid_data_loader, valid_loss, lr_scheduler)\n",
    "\n",
    "        if epoch % PRINT_EVERY == 0:\n",
    "            print(f\"Epoch {epoch}/{NUM_EPOCHS}, Loss {train_loss.avg}\")\n",
    "            print(f\"Fold {fold}, Valid Loss {valid_loss.avg} \\n\")\n",
    "        \n",
    "        # tq.set_postfix(val_loss=valid_loss.avg.item())\n",
    "\n",
    "        if valid_loss.avg < best_valid_loss:\n",
    "            best_valid_loss = valid_loss.avg\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, os.path.join(CONFIG.CFG.DATA.MODELS_OUT, f\"model_fold_{fold}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.upload_to_kaggle(\"osicqrmodel\", \"OSIC QR Model\", new=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for fold in range(K_FOLDS):\n",
    "    model = PulmonaryModel(len(FV))\n",
    "    model = model.to(DEVICE)\n",
    "    checkpoint = torch.load(os.path.join(CONFIG.CFG.DATA.MODELS_OUT, f\"model_fold_{fold}.pt\"))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = combined_df[combined_df['FROM'] == 'test'].reset_index(drop=True)\n",
    "test_dataset = PulmonaryDataset(new_test_df, FV)\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(730, 20)"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "new_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_preds = np.zeros((len(test_dataset), len(QUANTILES)))\n",
    "with torch.no_grad():\n",
    "    for model in models:\n",
    "        preds = []\n",
    "        for j, test_data in enumerate(test_data_loader):\n",
    "            features = test_data['features']\n",
    "            targets = test_data['target']\n",
    "\n",
    "            features = features.to(DEVICE).float()\n",
    "            targets = targets.to(DEVICE).float()\n",
    "\n",
    "            out = model(features)\n",
    "            preds.append(out)\n",
    "        preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "        avg_preds += preds\n",
    "avg_preds /= len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2898.08457031, 3142.53564453, 3377.50253906],\n       [2892.51005859, 3136.5050293 , 3371.03310547],\n       [2886.93530273, 3130.47456055, 3364.56391602],\n       ...,\n       [2028.98952637, 2202.49018555, 2369.36118164],\n       [2023.7012207 , 2196.76708984, 2363.21899414],\n       [2018.41291504, 2191.04406738, 2357.07675781]])"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(730, 10)"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = new_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['FVC'] = avg_preds[:, 1]\n",
    "temp_df['Confidence'] = np.abs(avg_preds[:, 2] - avg_preds[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv(\"view.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inverse the scaling operation for FVC\n",
    "# avg_preds -= MIN_MAX_SCALER.min_[SCALE_COLUMNS.index('FVC')]\n",
    "# avg_preds /= MIN_MAX_SCALER.scale_[SCALE_COLUMNS.index('FVC')]"
   ]
  }
 ]
}