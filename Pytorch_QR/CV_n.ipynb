{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath(os.pardir) not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath(os.pardir))\n",
    "import CONFIG\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CONFIG.CFG.DATA.BASE\n",
    "K_FOLDS = 5\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-4\n",
    "NUM_EPOCHS = 1100\n",
    "# print loss every\n",
    "PRINT_EVERY = 50\n",
    "\n",
    "QUANTILES = [0.2, 0.5, 0.8]\n",
    "SCALE_COLUMNS = ['Weeks', 'FVC', 'Percent', 'Age'] #'Percent'\n",
    "SCALE_COLUMNS = ['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']\n",
    "SEX_COLUMNS = ['Male', 'Female']\n",
    "SMOKING_STATUS_COLUMNS = ['Currently smokes', 'Ex-smoker', 'Never smoked']\n",
    "FV = SEX_COLUMNS + SMOKING_STATUS_COLUMNS + SCALE_COLUMNS\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.KFold(K_FOLDS)\n",
    "MIN_MAX_SCALER = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "sub_df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "# remove the duplicates from the train_df\n",
    "train_df.drop_duplicates(keep=False, inplace=True, subset=['Patient', 'Weeks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_Week</th>\n      <th>FVC</th>\n      <th>Confidence</th>\n      <th>Patient</th>\n      <th>Weeks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00419637202311204720264_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00421637202311550012437_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00421637202311550012437</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00422637202311677017371_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00422637202311677017371</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00423637202312137826377_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00423637202312137826377</td>\n      <td>-12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00426637202313170790466_-12</td>\n      <td>2000</td>\n      <td>100</td>\n      <td>ID00426637202313170790466</td>\n      <td>-12</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    Patient_Week   FVC  ...                    Patient Weeks\n0  ID00419637202311204720264_-12  2000  ...  ID00419637202311204720264   -12\n1  ID00421637202311550012437_-12  2000  ...  ID00421637202311550012437   -12\n2  ID00422637202311677017371_-12  2000  ...  ID00422637202311677017371   -12\n3  ID00423637202312137826377_-12  2000  ...  ID00423637202312137826377   -12\n4  ID00426637202313170790466_-12  2000  ...  ID00426637202313170790466   -12\n\n[5 rows x 5 columns]"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# extract the Patient and weeks from the Patient_Week column\n",
    "sub_df['Patient'] = sub_df['Patient_Week'].apply(lambda x: x.split('_')[0])\n",
    "sub_df['Weeks'] = sub_df['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00419637202311204720264_-12</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-12</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00419637202311204720264_-11</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-11</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00419637202311204720264_-10</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-10</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00419637202311204720264_-9</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-9</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00419637202311204720264_-8</td>\n      <td>100</td>\n      <td>ID00419637202311204720264</td>\n      <td>-8</td>\n      <td>3020</td>\n      <td>70.186855</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    Patient_Week  Confidence  ...   Sex  SmokingStatus\n0  ID00419637202311204720264_-12         100  ...  Male      Ex-smoker\n1  ID00419637202311204720264_-11         100  ...  Male      Ex-smoker\n2  ID00419637202311204720264_-10         100  ...  Male      Ex-smoker\n3   ID00419637202311204720264_-9         100  ...  Male      Ex-smoker\n4   ID00419637202311204720264_-8         100  ...  Male      Ex-smoker\n\n[5 rows x 9 columns]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# merge the sub_df with the test_df\n",
    "sub_df = sub_df.drop('FVC', axis=1).merge(test_df.drop('Weeks', axis=1), on='Patient')\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['FROM'] = 'train'\n",
    "test_df['FROM'] = 'val'\n",
    "sub_df['FROM'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(730, 10)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5, 8)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = train_df.append([test_df, sub_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize base_week column\n",
    "combined_df['Base_Week'] = combined_df['Weeks']\n",
    "# make the weeks from sub_df to be np.nan so that when we calculate the base_week it comes from the test_df\n",
    "combined_df.loc[combined_df['FROM'] == 'test', 'Base_Week'] = np.nan\n",
    "# now calculate the min for each patient group and set it to the Base_Week column\n",
    "combined_df['Base_Week'] = combined_df.groupby('Patient')['Base_Week'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the base_df (where the Base_Week == the min_week we calculated) so that we can get the base_fvc, base_age and base_percentage\n",
    "base_df = combined_df[combined_df['Weeks'] == combined_df['Base_Week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4133: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  errors=errors,\n"
    }
   ],
   "source": [
    "base_df.rename(columns={\n",
    "    'FVC': 'Base_FVC',\n",
    "    'Percent': 'Base_Percent',\n",
    "    'Age': 'Base_Age'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.merge(base_df[['Patient', 'Base_FVC', 'Base_Percent', 'Base_Age']], on='Patient', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3821</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3823</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3824</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        Patient  Weeks   FVC  ...  Base_FVC  Base_Percent Base_Age\n3821  ID00426637202313170790466    132  2925  ...      2925     71.824968       73\n3822  ID00426637202313170790466    132  2925  ...      2925     71.824968       73\n3823  ID00426637202313170790466    133  2925  ...      2925     71.824968       73\n3824  ID00426637202313170790466    133  2925  ...      2925     71.824968       73\n3825  ID00426637202313170790466    133  2925  ...      2925     71.824968       73\n\n[5 rows x 14 columns]"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Weeks_Passed'] = combined_df['Weeks'] - combined_df['Base_Week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3821</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3823</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3824</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Base_Age  Weeks_Passed\n3821  ID00426637202313170790466    132  ...        73         132.0\n3822  ID00426637202313170790466    132  ...        73         132.0\n3823  ID00426637202313170790466    133  ...        73         133.0\n3824  ID00426637202313170790466    133  ...        73         133.0\n3825  ID00426637202313170790466    133  ...        73         133.0\n\n[5 rows x 15 columns]"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MinMaxScaler(copy=True, feature_range=(0, 1))"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "MIN_MAX_SCALER.fit(combined_df[combined_df['FROM'] == 'train'][['Weeks_Passed', 'FVC', 'Percent', 'Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3821</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3822</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>3823</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3824</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>133.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Base_Age  Weeks_Passed\n3821  ID00426637202313170790466    132  ...        73         132.0\n3822  ID00426637202313170790466    132  ...        73         132.0\n3823  ID00426637202313170790466    133  ...        73         133.0\n3824  ID00426637202313170790466    133  ...        73         133.0\n3825  ID00426637202313170790466    133  ...        73         133.0\n\n[5 rows x 15 columns]"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']] = MIN_MAX_SCALER.transform(combined_df[['Weeks_Passed', 'Base_FVC', 'Base_Percent', 'Base_Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categoricals into dummies\n",
    "combined_df['Sex'] = pd.Categorical(combined_df['Sex'], categories=SEX_COLUMNS)\n",
    "combined_df['SmokingStatus'] = pd.Categorical(combined_df['SmokingStatus'], categories=SMOKING_STATUS_COLUMNS)\n",
    "combined_df = combined_df.join(pd.get_dummies(combined_df['Sex']))\n",
    "combined_df = combined_df.join(pd.get_dummies(combined_df['SmokingStatus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient</th>\n      <th>Weeks</th>\n      <th>FVC</th>\n      <th>Percent</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>SmokingStatus</th>\n      <th>FROM</th>\n      <th>Patient_Week</th>\n      <th>Confidence</th>\n      <th>Base_Week</th>\n      <th>Base_FVC</th>\n      <th>Base_Percent</th>\n      <th>Base_Age</th>\n      <th>Weeks_Passed</th>\n      <th>Male</th>\n      <th>Female</th>\n      <th>Currently smokes</th>\n      <th>Ex-smoker</th>\n      <th>Never smoked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID00007637202177411956430</td>\n      <td>-4</td>\n      <td>2315</td>\n      <td>58.253649</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID00007637202177411956430</td>\n      <td>5</td>\n      <td>2214</td>\n      <td>55.712129</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.142857</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID00007637202177411956430</td>\n      <td>7</td>\n      <td>2061</td>\n      <td>51.862104</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.174603</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID00007637202177411956430</td>\n      <td>9</td>\n      <td>2144</td>\n      <td>53.950679</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.206349</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID00007637202177411956430</td>\n      <td>11</td>\n      <td>2069</td>\n      <td>52.063412</td>\n      <td>79</td>\n      <td>Male</td>\n      <td>Ex-smoker</td>\n      <td>train</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n      <td>0.267050</td>\n      <td>0.236393</td>\n      <td>0.769231</td>\n      <td>0.238095</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2265</th>\n      <td>ID00426637202313170790466</td>\n      <td>129</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_129</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.047619</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2266</th>\n      <td>ID00426637202313170790466</td>\n      <td>130</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_130</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.063492</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2267</th>\n      <td>ID00426637202313170790466</td>\n      <td>131</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_131</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.079365</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2268</th>\n      <td>ID00426637202313170790466</td>\n      <td>132</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_132</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.095238</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2269</th>\n      <td>ID00426637202313170790466</td>\n      <td>133</td>\n      <td>2925</td>\n      <td>71.824968</td>\n      <td>73</td>\n      <td>Male</td>\n      <td>Never smoked</td>\n      <td>test</td>\n      <td>ID00426637202313170790466_133</td>\n      <td>100.0</td>\n      <td>0.0</td>\n      <td>0.376525</td>\n      <td>0.345604</td>\n      <td>0.615385</td>\n      <td>2.111111</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2270 rows × 20 columns</p>\n</div>",
      "text/plain": "                        Patient  Weeks  ...  Ex-smoker  Never smoked\n0     ID00007637202177411956430     -4  ...          1             0\n1     ID00007637202177411956430      5  ...          1             0\n2     ID00007637202177411956430      7  ...          1             0\n3     ID00007637202177411956430      9  ...          1             0\n4     ID00007637202177411956430     11  ...          1             0\n...                         ...    ...  ...        ...           ...\n2265  ID00426637202313170790466    129  ...          0             1\n2266  ID00426637202313170790466    130  ...          0             1\n2267  ID00426637202313170790466    131  ...          0             1\n2268  ID00426637202313170790466    132  ...          0             1\n2269  ID00426637202313170790466    133  ...          0             1\n\n[2270 rows x 20 columns]"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "combined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PulmonaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, FV, test=False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        self.FV = FV\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.df[self.FV].iloc[idx].values),\n",
    "            'target': torch.tensor(self.df['FVC'].iloc[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PulmonaryModel(nn.Module):\n",
    "    def __init__(self, in_features=9, out_quantiles=3):\n",
    "        super(PulmonaryModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, out_quantiles)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_one, clip_two = torch.tensor(70, dtype=torch.float32).to(DEVICE), torch.tensor(1000, dtype=torch.float32).to(DEVICE)\n",
    "def score(y_true, y_pred):\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "\n",
    "    sigma_clip = torch.max(sigma, clip_one)\n",
    "    delta = torch.abs(y_true - fvc_pred)\n",
    "    delta = torch.min(delta, clip_two)\n",
    "    sq2 = torch.sqrt(torch.tensor(2, dtype=torch.float32))\n",
    "    metric = (delta / sigma_clip) * sq2 + torch.log(sigma_clip * sq2)\n",
    "    return torch.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(preds, target, quantiles, _lambda):\n",
    "    assert not target.requires_grad\n",
    "    assert preds.size(0) == target.size(0)\n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = target - preds[:, i]\n",
    "        losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(1))\n",
    "    loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "    return loss\n",
    "    # return _lambda * loss + (1 - _lambda) * score(target, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_data_loader, optimizer, train_loss):\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_data_loader):\n",
    "        features = data['features']\n",
    "        targets = data['target']\n",
    "\n",
    "        features = features.to(DEVICE).float()\n",
    "        targets = targets.to(DEVICE).float()\n",
    "\n",
    "        model.zero_grad()\n",
    "        out = model(features)\n",
    "        loss = quantile_loss(out, targets, QUANTILES, 0.8)\n",
    "        train_loss.update(loss, features.size(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(model, valid_data_loader, valid_loss, lr_scheduler):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_data_loader):\n",
    "            features = data['features']\n",
    "            targets = data['target']\n",
    "\n",
    "            features = features.to(DEVICE).float()\n",
    "            targets = targets.to(DEVICE).float()\n",
    "            \n",
    "            out = model(features)\n",
    "            loss = quantile_loss(out, targets, QUANTILES, 0.8)\n",
    "            valid_loss.update(loss, features.size(0))\n",
    "    \n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step(valid_loss.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = combined_df[combined_df['FROM'] == 'train'].reset_index(drop=True)\n",
    "TRAIN_PATIENTS = new_train_df['Patient'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0/1100, Loss 4259.1845703125\nFold 0, Valid Loss 4547.5927734375 \n\nEpoch 50/1100, Loss 190.1754608154297\nFold 0, Valid Loss 344.79046630859375 \n\nEpoch 100/1100, Loss 163.3604278564453\nFold 0, Valid Loss 316.551025390625 \n\nEpoch 150/1100, Loss 155.99169921875\nFold 0, Valid Loss 308.6585693359375 \n\nEpoch 200/1100, Loss 152.85647583007812\nFold 0, Valid Loss 307.9645690917969 \n\nEpoch   213: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 250/1100, Loss 151.0522003173828\nFold 0, Valid Loss 310.0701904296875 \n\nEpoch   264: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 300/1100, Loss 149.253173828125\nFold 0, Valid Loss 309.4747314453125 \n\nEpoch   315: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 350/1100, Loss 151.10227966308594\nFold 0, Valid Loss 312.9024963378906 \n\nEpoch   366: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 400/1100, Loss 146.00204467773438\nFold 0, Valid Loss 311.5400390625 \n\nEpoch   417: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 450/1100, Loss 145.9116973876953\nFold 0, Valid Loss 310.9066467285156 \n\nEpoch   468: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 500/1100, Loss 145.04644775390625\nFold 0, Valid Loss 312.2425842285156 \n\nEpoch   519: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 550/1100, Loss 145.40557861328125\nFold 0, Valid Loss 312.110107421875 \n\nEpoch   570: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 600/1100, Loss 144.83285522460938\nFold 0, Valid Loss 310.46368408203125 \n\nEpoch   621: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 650/1100, Loss 144.42550659179688\nFold 0, Valid Loss 311.6967468261719 \n\nEpoch   672: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 700/1100, Loss 144.39283752441406\nFold 0, Valid Loss 311.903076171875 \n\nEpoch   723: reducing learning rate of group 0 to 9.8866e-06.\nEpoch 750/1100, Loss 144.29287719726562\nFold 0, Valid Loss 311.9272155761719 \n\nEpoch   774: reducing learning rate of group 0 to 6.9206e-06.\nEpoch 800/1100, Loss 144.3140106201172\nFold 0, Valid Loss 311.9815673828125 \n\nEpoch   825: reducing learning rate of group 0 to 4.8445e-06.\nEpoch 850/1100, Loss 144.20628356933594\nFold 0, Valid Loss 312.1593017578125 \n\nEpoch   876: reducing learning rate of group 0 to 3.3911e-06.\nEpoch 900/1100, Loss 144.20115661621094\nFold 0, Valid Loss 312.1500549316406 \n\nEpoch   927: reducing learning rate of group 0 to 2.3738e-06.\nEpoch 950/1100, Loss 144.1545867919922\nFold 0, Valid Loss 312.0377502441406 \n\nEpoch   978: reducing learning rate of group 0 to 1.6616e-06.\nEpoch 1000/1100, Loss 144.14425659179688\nFold 0, Valid Loss 312.0548095703125 \n\nEpoch  1029: reducing learning rate of group 0 to 1.1632e-06.\nEpoch 1050/1100, Loss 144.13226318359375\nFold 0, Valid Loss 312.15045166015625 \n\nEpoch  1080: reducing learning rate of group 0 to 8.1421e-07.\nEpoch 0/1100, Loss 4301.1162109375\nFold 1, Valid Loss 4386.615234375 \n\nEpoch 50/1100, Loss 263.7873229980469\nFold 1, Valid Loss 201.25741577148438 \n\nEpoch 100/1100, Loss 211.5400390625\nFold 1, Valid Loss 176.56910705566406 \n\nEpoch 150/1100, Loss 190.74595642089844\nFold 1, Valid Loss 171.6901397705078 \n\nEpoch   197: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 200/1100, Loss 188.10223388671875\nFold 1, Valid Loss 173.60914611816406 \n\nEpoch   248: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 250/1100, Loss 188.6342010498047\nFold 1, Valid Loss 173.27938842773438 \n\nEpoch   299: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 300/1100, Loss 183.88267517089844\nFold 1, Valid Loss 174.6442108154297 \n\nEpoch   350: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 350/1100, Loss 181.06951904296875\nFold 1, Valid Loss 172.07020568847656 \n\nEpoch   401: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 400/1100, Loss 182.9859619140625\nFold 1, Valid Loss 172.7600555419922 \n\nEpoch 450/1100, Loss 180.10507202148438\nFold 1, Valid Loss 170.22193908691406 \n\nEpoch   452: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 500/1100, Loss 179.7111053466797\nFold 1, Valid Loss 169.8109893798828 \n\nEpoch   503: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 550/1100, Loss 180.04769897460938\nFold 1, Valid Loss 169.8532257080078 \n\nEpoch   580: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 600/1100, Loss 179.3843231201172\nFold 1, Valid Loss 167.7751922607422 \n\nEpoch   631: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 650/1100, Loss 179.1584014892578\nFold 1, Valid Loss 167.5330047607422 \n\nEpoch   682: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 700/1100, Loss 179.10446166992188\nFold 1, Valid Loss 168.4336395263672 \n\nEpoch   733: reducing learning rate of group 0 to 9.8866e-06.\nEpoch 750/1100, Loss 179.06546020507812\nFold 1, Valid Loss 168.7734832763672 \n\nEpoch   784: reducing learning rate of group 0 to 6.9206e-06.\nEpoch 800/1100, Loss 178.89610290527344\nFold 1, Valid Loss 168.67672729492188 \n\nEpoch   835: reducing learning rate of group 0 to 4.8445e-06.\nEpoch 850/1100, Loss 178.8368377685547\nFold 1, Valid Loss 169.0103302001953 \n\nEpoch   886: reducing learning rate of group 0 to 3.3911e-06.\nEpoch 900/1100, Loss 178.83157348632812\nFold 1, Valid Loss 169.26620483398438 \n\nEpoch   937: reducing learning rate of group 0 to 2.3738e-06.\nEpoch 950/1100, Loss 178.8004913330078\nFold 1, Valid Loss 169.18214416503906 \n\nEpoch   988: reducing learning rate of group 0 to 1.6616e-06.\nEpoch 1000/1100, Loss 178.7630615234375\nFold 1, Valid Loss 169.1757049560547 \n\nEpoch  1039: reducing learning rate of group 0 to 1.1632e-06.\nEpoch 1050/1100, Loss 178.75808715820312\nFold 1, Valid Loss 169.2723388671875 \n\nEpoch  1090: reducing learning rate of group 0 to 8.1421e-07.\nEpoch 0/1100, Loss 4517.087890625\nFold 2, Valid Loss 3515.362548828125 \n\nEpoch 50/1100, Loss 251.0919647216797\nFold 2, Valid Loss 166.1432647705078 \n\nEpoch    91: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 100/1100, Loss 209.80990600585938\nFold 2, Valid Loss 180.07040405273438 \n\nEpoch   142: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 150/1100, Loss 204.38128662109375\nFold 2, Valid Loss 186.64315795898438 \n\nEpoch   193: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 200/1100, Loss 194.8020782470703\nFold 2, Valid Loss 207.00729370117188 \n\nEpoch   244: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 250/1100, Loss 191.3199005126953\nFold 2, Valid Loss 206.43661499023438 \n\nEpoch   295: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 300/1100, Loss 190.60885620117188\nFold 2, Valid Loss 208.21058654785156 \n\nEpoch   346: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 350/1100, Loss 188.38453674316406\nFold 2, Valid Loss 210.3369598388672 \n\nEpoch   397: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 400/1100, Loss 187.8261260986328\nFold 2, Valid Loss 210.01292419433594 \n\nEpoch   448: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 450/1100, Loss 186.91473388671875\nFold 2, Valid Loss 211.89459228515625 \n\nEpoch   499: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 500/1100, Loss 186.5283660888672\nFold 2, Valid Loss 210.3749237060547 \n\nEpoch   550: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 550/1100, Loss 186.43582153320312\nFold 2, Valid Loss 207.76866149902344 \n\nEpoch   601: reducing learning rate of group 0 to 9.8866e-06.\nEpoch 600/1100, Loss 185.97341918945312\nFold 2, Valid Loss 212.0531005859375 \n\nEpoch 650/1100, Loss 185.9859619140625\nFold 2, Valid Loss 209.8468780517578 \n\nEpoch   652: reducing learning rate of group 0 to 6.9206e-06.\nEpoch 700/1100, Loss 185.8046417236328\nFold 2, Valid Loss 212.05801391601562 \n\nEpoch   703: reducing learning rate of group 0 to 4.8445e-06.\nEpoch 750/1100, Loss 185.666748046875\nFold 2, Valid Loss 212.47100830078125 \n\nEpoch   754: reducing learning rate of group 0 to 3.3911e-06.\nEpoch 800/1100, Loss 185.66835021972656\nFold 2, Valid Loss 212.5819091796875 \n\nEpoch   805: reducing learning rate of group 0 to 2.3738e-06.\nEpoch 850/1100, Loss 185.60630798339844\nFold 2, Valid Loss 211.96707153320312 \n\nEpoch   856: reducing learning rate of group 0 to 1.6616e-06.\nEpoch 900/1100, Loss 185.57823181152344\nFold 2, Valid Loss 211.6491241455078 \n\nEpoch   907: reducing learning rate of group 0 to 1.1632e-06.\nEpoch 950/1100, Loss 185.57455444335938\nFold 2, Valid Loss 211.49993896484375 \n\nEpoch   958: reducing learning rate of group 0 to 8.1421e-07.\nEpoch 1000/1100, Loss 185.56004333496094\nFold 2, Valid Loss 210.99684143066406 \n\nEpoch  1009: reducing learning rate of group 0 to 5.6994e-07.\nEpoch 1050/1100, Loss 185.55276489257812\nFold 2, Valid Loss 211.0414276123047 \n\nEpoch  1060: reducing learning rate of group 0 to 3.9896e-07.\nEpoch 0/1100, Loss 4231.7216796875\nFold 3, Valid Loss 4665.17822265625 \n\nEpoch 50/1100, Loss 240.27354431152344\nFold 3, Valid Loss 421.64990234375 \n\nEpoch 100/1100, Loss 200.03350830078125\nFold 3, Valid Loss 240.65052795410156 \n\nEpoch 150/1100, Loss 185.34996032714844\nFold 3, Valid Loss 232.15658569335938 \n\nEpoch 200/1100, Loss 180.03961181640625\nFold 3, Valid Loss 253.94342041015625 \n\nEpoch   213: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 250/1100, Loss 166.95748901367188\nFold 3, Valid Loss 229.51495361328125 \n\nEpoch   264: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 300/1100, Loss 162.677734375\nFold 3, Valid Loss 231.936767578125 \n\nEpoch   315: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 350/1100, Loss 164.7665252685547\nFold 3, Valid Loss 233.1007080078125 \n\nEpoch   366: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 400/1100, Loss 160.40744018554688\nFold 3, Valid Loss 239.19378662109375 \n\nEpoch   417: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 450/1100, Loss 158.960693359375\nFold 3, Valid Loss 236.77841186523438 \n\nEpoch   468: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 500/1100, Loss 157.63963317871094\nFold 3, Valid Loss 235.74420166015625 \n\nEpoch   519: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 550/1100, Loss 157.33697509765625\nFold 3, Valid Loss 239.96592712402344 \n\nEpoch   570: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 600/1100, Loss 157.11959838867188\nFold 3, Valid Loss 238.42672729492188 \n\nEpoch   621: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 650/1100, Loss 156.72499084472656\nFold 3, Valid Loss 238.61953735351562 \n\nEpoch   672: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 700/1100, Loss 156.49082946777344\nFold 3, Valid Loss 238.63192749023438 \n\nEpoch   723: reducing learning rate of group 0 to 9.8866e-06.\nEpoch 750/1100, Loss 156.32252502441406\nFold 3, Valid Loss 238.62738037109375 \n\nEpoch   774: reducing learning rate of group 0 to 6.9206e-06.\nEpoch 800/1100, Loss 156.3289794921875\nFold 3, Valid Loss 238.1396484375 \n\nEpoch   825: reducing learning rate of group 0 to 4.8445e-06.\nEpoch 850/1100, Loss 156.2892608642578\nFold 3, Valid Loss 237.7761993408203 \n\nEpoch   876: reducing learning rate of group 0 to 3.3911e-06.\nEpoch 900/1100, Loss 156.16851806640625\nFold 3, Valid Loss 238.01986694335938 \n\nEpoch   927: reducing learning rate of group 0 to 2.3738e-06.\nEpoch 950/1100, Loss 156.1761016845703\nFold 3, Valid Loss 237.4109649658203 \n\nEpoch   978: reducing learning rate of group 0 to 1.6616e-06.\nEpoch 1000/1100, Loss 156.14561462402344\nFold 3, Valid Loss 237.59149169921875 \n\nEpoch  1029: reducing learning rate of group 0 to 1.1632e-06.\nEpoch 1050/1100, Loss 156.1459503173828\nFold 3, Valid Loss 237.44366455078125 \n\nEpoch  1080: reducing learning rate of group 0 to 8.1421e-07.\nEpoch 0/1100, Loss 4283.28125\nFold 4, Valid Loss 4460.40673828125 \n\nEpoch 50/1100, Loss 229.1875762939453\nFold 4, Valid Loss 255.27273559570312 \n\nEpoch 100/1100, Loss 191.92384338378906\nFold 4, Valid Loss 236.18878173828125 \n\nEpoch 150/1100, Loss 194.45016479492188\nFold 4, Valid Loss 233.11941528320312 \n\nEpoch 200/1100, Loss 188.44078063964844\nFold 4, Valid Loss 227.97186279296875 \n\nEpoch 250/1100, Loss 187.1533966064453\nFold 4, Valid Loss 205.9342498779297 \n\nEpoch 300/1100, Loss 178.79322814941406\nFold 4, Valid Loss 208.8219451904297 \n\nEpoch 350/1100, Loss 185.90872192382812\nFold 4, Valid Loss 200.0229034423828 \n\nEpoch 400/1100, Loss 177.04586791992188\nFold 4, Valid Loss 183.5714874267578 \n\nEpoch 450/1100, Loss 174.35841369628906\nFold 4, Valid Loss 189.623779296875 \n\nEpoch   496: reducing learning rate of group 0 to 3.5000e-04.\nEpoch 500/1100, Loss 170.11167907714844\nFold 4, Valid Loss 180.00169372558594 \n\nEpoch 550/1100, Loss 164.065185546875\nFold 4, Valid Loss 180.548583984375 \n\nEpoch   578: reducing learning rate of group 0 to 2.4500e-04.\nEpoch 600/1100, Loss 173.95706176757812\nFold 4, Valid Loss 175.25103759765625 \n\nEpoch   629: reducing learning rate of group 0 to 1.7150e-04.\nEpoch 650/1100, Loss 161.3970489501953\nFold 4, Valid Loss 176.31419372558594 \n\nEpoch 700/1100, Loss 160.9095916748047\nFold 4, Valid Loss 175.29342651367188 \n\nEpoch   728: reducing learning rate of group 0 to 1.2005e-04.\nEpoch 750/1100, Loss 158.89759826660156\nFold 4, Valid Loss 173.02687072753906 \n\nEpoch   779: reducing learning rate of group 0 to 8.4035e-05.\nEpoch 800/1100, Loss 162.84225463867188\nFold 4, Valid Loss 171.11679077148438 \n\nEpoch   830: reducing learning rate of group 0 to 5.8824e-05.\nEpoch 850/1100, Loss 157.71429443359375\nFold 4, Valid Loss 169.96778869628906 \n\nEpoch   881: reducing learning rate of group 0 to 4.1177e-05.\nEpoch 900/1100, Loss 157.38331604003906\nFold 4, Valid Loss 171.2606658935547 \n\nEpoch   932: reducing learning rate of group 0 to 2.8824e-05.\nEpoch 950/1100, Loss 157.1102294921875\nFold 4, Valid Loss 170.93299865722656 \n\nEpoch   983: reducing learning rate of group 0 to 2.0177e-05.\nEpoch 1000/1100, Loss 156.79562377929688\nFold 4, Valid Loss 171.33140563964844 \n\nEpoch  1034: reducing learning rate of group 0 to 1.4124e-05.\nEpoch 1050/1100, Loss 156.43319702148438\nFold 4, Valid Loss 170.53109741210938 \n\nEpoch  1085: reducing learning rate of group 0 to 9.8866e-06.\n"
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(kf.split(TRAIN_PATIENTS)):\n",
    "    model = PulmonaryModel(len(FV))\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    train_patient_ids = TRAIN_PATIENTS[train_index]\n",
    "    valid_patient_ids = TRAIN_PATIENTS[test_index]\n",
    "\n",
    "    df_train = new_train_df[new_train_df['Patient'].isin(train_patient_ids)].reset_index(drop=True)\n",
    "    df_valid = new_train_df[new_train_df['Patient'].isin(valid_patient_ids)].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = PulmonaryDataset(df_train, FV)\n",
    "    valid_dataset = PulmonaryDataset(df_valid, FV)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=10,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=50, factor=0.7, verbose=True)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    \n",
    "    # tq = tqdm(range(NUM_EPOCHS), desc=f\"Fold {fold}\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = AverageMeter()\n",
    "        valid_loss = AverageMeter()\n",
    "\n",
    "        train_one_epoch(model, train_data_loader, optimizer, train_loss)\n",
    "        eval_one_epoch(model, valid_data_loader, valid_loss, lr_scheduler)\n",
    "\n",
    "        if epoch % PRINT_EVERY == 0:\n",
    "            print(f\"Epoch {epoch}/{NUM_EPOCHS}, Loss {train_loss.avg}\")\n",
    "            print(f\"Fold {fold}, Valid Loss {valid_loss.avg} \\n\")\n",
    "        \n",
    "        # tq.set_postfix(val_loss=valid_loss.avg.item())\n",
    "\n",
    "        if valid_loss.avg < best_valid_loss:\n",
    "            best_valid_loss = valid_loss.avg\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, os.path.join(CONFIG.CFG.DATA.MODELS_OUT, f\"model_fold_{fold}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.upload_to_kaggle(\"osicqrmodel\", \"OSIC QR Model\", new=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for fold in range(K_FOLDS):\n",
    "    model = PulmonaryModel(len(FV))\n",
    "    model = model.to(DEVICE)\n",
    "    checkpoint = torch.load(os.path.join(CONFIG.CFG.DATA.MODELS_OUT, f\"model_fold_{fold}.pt\"))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = combined_df[combined_df['FROM'] == 'test'].reset_index(drop=True)\n",
    "test_dataset = PulmonaryDataset(new_test_df, FV)\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(730, 20)"
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "new_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_preds = np.zeros((len(test_dataset), len(QUANTILES)))\n",
    "with torch.no_grad():\n",
    "    for model in models:\n",
    "        preds = []\n",
    "        for j, test_data in enumerate(test_data_loader):\n",
    "            features = test_data['features']\n",
    "            targets = test_data['target']\n",
    "\n",
    "            features = features.to(DEVICE).float()\n",
    "            targets = targets.to(DEVICE).float()\n",
    "\n",
    "            out = model(features)\n",
    "            preds.append(out)\n",
    "        preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "        avg_preds += preds\n",
    "avg_preds /= len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2898.08457031, 3142.53564453, 3377.50253906],\n       [2892.51005859, 3136.5050293 , 3371.03310547],\n       [2886.93530273, 3130.47456055, 3364.56391602],\n       ...,\n       [2028.98952637, 2202.49018555, 2369.36118164],\n       [2023.7012207 , 2196.76708984, 2363.21899414],\n       [2018.41291504, 2191.04406738, 2357.07675781]])"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(730, 10)"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = new_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['FVC'] = avg_preds[:, 1]\n",
    "temp_df['Confidence'] = np.abs(avg_preds[:, 2] - avg_preds[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv(\"view.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inverse the scaling operation for FVC\n",
    "# avg_preds -= MIN_MAX_SCALER.min_[SCALE_COLUMNS.index('FVC')]\n",
    "# avg_preds /= MIN_MAX_SCALER.scale_[SCALE_COLUMNS.index('FVC')]"
   ]
  }
 ]
}