{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath(os.pardir) not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath(os.pardir))\n",
    "import CONFIG\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = CONFIG.CFG.DATA.BASE\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# number of images used to create a single 3D array of the scan\n",
    "NUM_IMAGES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATIENTS = train_df['Patient'].unique().tolist()\n",
    "# gave the gdcm error\n",
    "BAD_PATIENT_IDS = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "ALL_TRAIN_PATIENTS = [pat for pat in TRAIN_PATIENTS if pat not in BAD_PATIENT_IDS]\n",
    "ALL_TEST_PATIENTS = test_df['Patient'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(DATA_DIR, \"train\", TRAIN_PATIENTS[4])\n",
    "all_files = os.listdir(path)\n",
    "all_files.sort(key = lambda x: int(x.split('.')[0]))\n",
    "slices = [pydicom.read_file(os.path.join(path, s)) for s in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_slices(patient_id, folder_path, num_images):\n",
    "    # the preprocessed array with NUM_SLICES elements\n",
    "    # TODO: Handle the case when the NUM_SLICES > the actual total slices\n",
    "    # TODO: resize the image to 256 X 256?\n",
    "\n",
    "    full_path = os.path.join(folder_path, patient_id)\n",
    "    # list of all files in that path and sort them\n",
    "    all_files = os.listdir(full_path)\n",
    "    # sorted using the first number part of the file name\n",
    "    all_files.sort(key = lambda x: int(x.split('.')[0]))\n",
    "\n",
    "    # read all the dicom files for the patient into the slices list\n",
    "    slices = [pydicom.read_file(os.path.join(full_path, s)) for s in all_files]\n",
    "    # sort the slices using their order (file number works too)\n",
    "    # slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "\n",
    "    # final array containing averaged num_images images\n",
    "    out_array = []\n",
    "\n",
    "    # how many extra files while averaging all images into (num_images) images\n",
    "    remainder_array_size = len(slices)%num_images\n",
    "\n",
    "    # how many to average to get a single averaged image\n",
    "    avging_array_size = len(slices)//num_images\n",
    "\n",
    "    # get the first one with the remainder images\n",
    "    first_array = []\n",
    "    # select the first remainder + avg_arrray_size imgaes and average into one\n",
    "    for slice in slices[:remainder_array_size+avging_array_size]:\n",
    "        first_array.append(slice.pixel_array)\n",
    "    first_avged_array = np.average(first_array, axis=0)\n",
    "    out_array.append(first_avged_array)\n",
    "\n",
    "    # after the first one get the remaining ones into out_array rolling averaging (avging_array_size) at a time.\n",
    "    for i in range(remainder_array_size + avging_array_size, len(slices), avging_array_size):\n",
    "        temp_array = []\n",
    "        for slice in slices[i:i+avging_array_size]:\n",
    "            temp_array.append(slice.pixel_array)\n",
    "        avged_temp_array = np.average(temp_array, axis=0)\n",
    "        out_array.append(avged_temp_array)\n",
    "    \n",
    "    return np.array(out_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_from_id = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the train and test images in array_from_id\n",
    "for id in ALL_TRAIN_PATIENTS:\n",
    "    array_from_id[id] = get_averaged_slices(id, os.path.join(DATA_DIR, \"train\"), NUM_IMAGES)\n",
    "\n",
    "for id in ALL_TEST_PATIENTS:\n",
    "    array_from_id[id] = get_averaged_slices(id, os.path.join(DATA_DIR, \"test\"), NUM_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PulmonaryDataset(Dataset):\n",
    "    def __init__(self, df, FV, test=False):\n",
    "        self.df = df\n",
    "        self.test = test\n",
    "        self.FV = FV\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'imgarray': torch.from_numpy(array_from_id[self.df.iloc[idx]['Patient']]),\n",
    "            'tabfeatures': torch.tensor(self.df[self.FV].iloc[idx].values),\n",
    "            'target': torch.tensor(self.df['FVC'].iloc[idx])\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 843, 888)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 768, 768)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 733, 888)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 768, 768)\n(8, 788, 888)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 752, 888)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 768, 768)\n(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 1302, 1302)\n(8, 512, 512)\n(8, 512, 512)\n(8, 734, 888)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 752, 888)\n(8, 512, 512)\n(8, 768, 768)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 632, 632)\n(8, 768, 768)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 768, 768)\n(8, 768, 768)\n(8, 512, 512)\n(8, 632, 632)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n(8, 768, 768)\n(8, 512, 512)\n(8, 1100, 888)\n(8, 768, 768)\n(8, 512, 512)\n(8, 512, 512)\n(8, 512, 512)\n"
    }
   ],
   "source": [
    "for key in array_from_id:\n",
    "    print(array_from_id[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}